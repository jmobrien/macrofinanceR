transform_nl <-
  function(dat_ts, nl){

    ## applies a simple nonlinear transformation (see paper for details), and calculates
    ## appropriate jacobian term to put in likelihood (for correct model comparison, or
    ## inference over the nl parameters).

    att <- nl[1] ## lower treshold
    ct <- nl[2] ## upper
    beta <- nl[3] ## slope increase
    iv <- nl[4] ## which variable to worry about
    ## alpha <- nl[5] ## slope of the original log transformation (x-p) - ky

    iseries <- dat_ts[,iv]

    jterm <- rep(0,length(iseries)) ## jacobian term

    ## quadratic range
    a1 <- beta / (2 * (ct - att))
    a2 <- 1 - 2 * att * a1
    a3 <- att - a2 *att - a1 * att^2

    iseries[(iseries > att) & (iseries < ct)] <-
      a3 + a2 * (iseries[(iseries > att) & (iseries < ct)]) +
      a1 * (iseries[(iseries > att) & (iseries < ct)])^2

    jterm <-
      sum(log(a2 + 2 * a1 * (dat_ts[(dat_ts[,iv] > att) & (dat_ts[,iv] < ct),iv])))


    ## upper linear range
    ct2 <- a3 + a2*ct + a1 * ct^2 ## f(ct)

    iseries[(dat_ts[,iv] >= ct)] <-
      (1+beta) * (iseries[(dat_ts[,iv] >= ct)] - ct) + ct2
    jterm <- jterm + sum(dat_ts[,iv] > ct) * log(1+beta)

    ## grDevices::pdf('~/check.pdf')
    ## ## irange <- (mydata[,iv] > att) & (mydata[,iv] < ct)
    ## ## plot(mydata[irange,iv],iseries[irange])
    ## plot(mydata[,iv],iseries,type <- 'l')
    ## dev.off()


    dat_ts[,iv] <- iseries

    return(list(dat_ts = dat_ts, jterm = jterm))
  }


## Allows for full regime switching for A0
## Karthik Sastry
## July 1 2019

## Allows for full regime switching for A0
## Karthik Sastry
## July 1 2019


bvarwrap_tvA <-
  function(x, verbose=FALSE, dat = NULL, n_lags = 2,
           lc_A0 = NULL, lc_lmd = NULL, lmdblock = NULL,
           breaks_pos = NULL, prior_params = NULL, # n_varcores = 1,
           dprior = TRUE,
           hparam_nl = rep(0,5), nlt = nlt, hparam = rep(0,7),
           lmdmean = FALSE,lmdPrior = NULL,
           oweights = NULL, drawbe = FALSE) {

    ## Main function for calculating log posterior used in Metropolis step

    ## Implements a Dirichlet prior on the variances, and assumes A0 diagonal is estimated

    ## -------------------- INPUTS --------------------X
    ## x: vector with all elements of A0, Lambda
    ## verbose: flag of whether to report more than the negative LLH. FALSE is useful
    ## for (some) Metropolis Hastings
    ## dat: data, in a specific format generated by other functions (see TvvDir and example scripts)
    ## n_lags: number of lags
    ## lc_A0: matrix of TRUE and FALSE indicating which elements of A0 to fill.
    ##       "unfilled" parts of matrix are diagonal
    ## lc_lmd: the full "Lmd" matrix is nshock x nregime. lc_lmd determines what parts
    ##        to fill with estimated params (in a more complicated way,
    ##        based on next arg. lmdblock, program will fill in the unspecified lambdas).
    ##        The last regime is always filled out by normalization
    ##        as nRegimes - sum(variances in previous regimes), so the arithmetic average is always
    ##        1. This is in lieu of any normalization of A0 and consistent with
    ##        a Dirichlet prior on the variances
    ## lmdblock: specifies exactly how to restrict some variances not to be
    ##        time-varying. Not used in the most recent calculations
    ## breaks_pos: vector of indices (i.e., integers) specifying the start and end
    ##        points of variance regimes. To avoid an error in counting, easiest to let
    ##        other programs populate this (you can input break points as a date string in
    ##        all the higher level programs)
    ## prior_params: struct that contains the VAR prior parameters, which are set in higher level functions.
    ## n_varcores: deprecated option for using multicore processing in calculating the
    ##           equation by equation OLS for the VAR
    ## dprior: if TRUE, use a dirichlet prior. Currently the implementation
    ##         is not very elegant, so you have to go into the code to change the parameters

    ## nlt: these are fixed parameters for the non-linear transformation. see associated functions for more info
    ## hparam_nl: these indicate (with 0 or 1) which paramters of the non-linear
    ##            transformation are being looped over (and hence added to the end of x)
    ## hparam: these indicate which prior parameters, numbered 1 to 7,
    ##         are being looped over (and included in x); i.e., being treated as heirarchical
    ##         currently: cannot loop over these and the non-linear transformation parameters

    ## lmdmean and lmdPrior: not used anymore

    ## oweights: weights on each observation to pass to likelihood
    ##          evalulation step. These are for the normal mixture models (i.e,. the "variance shocks" for each
    ##           observation)
    ## drawbe: if yes, draw the reduced form coefficients and residuals (necessary for normal mixture models)

    ## -------------------- OUTPUT --------------------
    ## if not verbose: just lh, which is the negative log posterior
    ## if verbose: lh plus a bunch of other stuff from the VAR calculation. You want this
    ##             for the normal mixture model (because it has the residuals and A_i coefficients)

    ## END PREAMBLE

    ## Preparing and formatting data

    ## Things that don't change, like nVar and Tobs, /should/ be bound outside
    ## the iteration, but performance gains are probably small

    nSig <- length(breaks_pos)              #number of regimes
    nVar <- dim(dat)[2]           #number of variables
    Tobs <- dim(dat)[1]

    A <- array(0, c(nVar, nVar, nSig))   #different A matrix for each regime

    varnames <- dimnames(dat)[[2]]


    ## Preparing A ----

    nA <- sum(lc_A0)         #number of non-fixed parameters, per regime
    Acoef <- matrix(x[1:(nA*nSig)],nrow=nA,ncol=nSig) #A parameters per regime

    for (iSig in 1:nSig){                            # fill A matrix
      Amat <- matrix(0,nVar,nVar)
      Amat[lc_A0] <- Acoef[,iSig]
      A[,,iSig] <- Amat
    }

    ## dimnames(A) <- list(varnames, varnames)
    nv <- dim(A)[1]

    ## Prior on A ----

    ## Adjusts for number of non-restircted values in A
    allh <- rep(0,nSig)
    nP <- sum(lc_A0)                      # number of parameters
    for (iSig in 1:nSig){               # looping over regimes

      Ascore <- (A[,,iSig] - diag(nVar) * 100)^2 / 4e4

      allh[iSig] <- -.5 * sum(Ascore[lc_A0]) - # subset to nonzero coefficients
        .5 * nP * (log (2 * pi) + log(200))
    }

    allh <- sum(allh)                    # summing over all variance regimes



    ## Preparing lmd ----

    if (length(x) == nA * nSig){
      ## No variance parameters to estimate
      hasLmd <- FALSE
      lmd <- matrix(1, nVar, nSig)

      nLmd <- 0

    } else {
      ## Fill in variance parameters
      hasLmd <- TRUE

      nLmd <- sum(lc_lmd)                   # maximum number of variance parameters to estimate
      lmd <- matrix(0, nVar, nSig)

      lmd[lc_lmd] <- x[(nA*nSig) + (1 : nLmd)]


      ## This is a streamlined way of setting certain lambda not to change between periods
      if (!is.null(lmdblock)) {
        nBlocks <- dim(lmdblock)[3]
        for (iBlock in 1:nBlocks){
          lmd[lmdblock[,,iBlock]] <- (lmd[lmdblock[,,iBlock]])[1]
          ##first of block was filled in
        }
      }

      ## last period's variances are fixed, so (arithmetic) average is 1
      ## ## lmd[,nSig] <- -log(nSig - apply(exp(-lmd[,1:(nSig-1)]),1,sum))
      lmd[,nSig] <- nSig - apply(lmd[,1:(nSig-1),drop=FALSE],1,sum)

      ## prior on lmd is applied later in the code

    }




    ## possible hyperparameters for the non-linear transformation
    lastvalue <- nA + nLmd ## for picking out extra params

    ## if (length(x) > (nA + nLmd)){
    if (any(hparam_nl > 0)) { ## better to check this, so we can still optimize over prior params

      ## input is A, C, beta, index of param
      ## never put a prior on the last one! that would be silly
      ## dont change the 5th either, because its applied outside the function

      ## nlt[hparam_nl > 0] <- x[-(1:(nA + nLmd))]
      nlt[hparam_nl > 0] <- x[lastvalue + 1:(sum(hparam_nl > 0))]
      lastvalue <- lastvalue + sum(hparam_nl > 0)

      nlflag <- TRUE

      nlout <- transform_nl(dat, nlt) ## apply nl transform

      dat <- nlout$data ## new data
      jterm <- nlout$jterm

      pterm <- sum(hparam_nl * nlt) ## neg exponential

    } else {
      nlflag <- FALSE ## no nonlinear transformation
      jterm <- 0
      pterm <- 0
    }

    if (any(hparam > 0)){ ## hyperparameters

      ## (MN tight, MN decay, UR lambda, UR mu,
      ## Cos tight, cos smooth, cos damp


      ## asume there is one of mn or cos prior
      if (!is.null(prior_params$cos_prior)){
        pv <- c(0,
                0,
                prior_params$ur_prior$lambda,
                prior_params$ur_prior$mu,
                prior_params$cos_prior$tight,
                prior_params$cos_prior$smooth,
                prior_params$cos_prior$damp)

        pv[(hparam > 0)] <- x[lastvalue + 1:(sum(hparam > 0))]
        ## prior_params$mn_prior$tight <- pv[1]
        ## prior_params$mn_prior$decay <- pv[2]
        prior_params$ur_prior$lambda <- pv[3]
        prior_params$ur_prior$mu <- pv[4]
        prior_params$cos_prior$tight <- pv[5]
        prior_params$cos_prior$smooth <- pv[6]
        prior_params$cos_prior$damp <- pv[7]

      } else { ## asume mn prior

        pv <- c(prior_params$mn_prior$tight,
                prior_params$mn_prior$decay,
                prior_params$ur_prior$lambda,
                prior_params$ur_prior$mu,
                0,
                0,
                0)

        pv[(hparam > 0)] <- x[lastvalue + 1:(sum(hparam > 0))]
        prior_params$mn_prior$tight <- pv[1]
        prior_params$mn_prior$decay <- pv[2]
        prior_params$ur_prior$lambda <- pv[3]
        prior_params$ur_prior$mu <- pv[4]
        ## prior_params$cos_prior$tight <- pv[5]
        ## prior_params$cos_prior$smooth <- pv[6]
        ## prior_params$cos_prior$damp <- pv[7]

      }



      ## if (!is.null(prior_params$mn_prior)){
      ##     prior_params$mn_prior$tight  <- pv[1]
      ##     prior_params$mn_prior$decay  <- pv[2]
      ## } else if (!is.null(prior_params$ur_prior)){
      ##     prior_params$ur_prior$lambda <- pv[3]
      ##     prior_params$ur_prior$mu     <- pv[4]
      ## }

      prior_hp <- sum(hparam * pv) ## neg exponential density
      badflag <- any(pv < 0)
    } else {
      prior_hp <- 0
      badflag <- FALSE
    }



    ## Estimating the model ----


    if (is.null(prior_params$mn_start)) prior_params$mn_start <- 1

    if (any(lmd < 0)){
      ## trash this draw, variances negative

      lh <- 1e5
      vout <- NULL

      if (!verbose){
        return(lh) #### dont need anything else
      } else {
        return(list(lh = lh))
      }


    } else if(nlflag && any(nlt < 0)){
      ## none of the nonlinear transformation parameters can be negative
      lh <- 1e5
      vout <- NULL
      ## return(lh)

      if (!verbose){
        return(lh) #### dont need anything else
      } else {
        return(list(lh = lh))
      }


    } else if(badflag){
      ## hyperparameter cannot be negative
      lh <- 1e5
      vout <- NULL
      ## return(lh)

      if (!verbose){
        return(lh) #### dont need anything else
      } else {
        return(list(lh = lh))
      }

    } else { #### proceed normally

      vout <- SVARhtskdmdd(dat, n_lags = n_lags, xdata = NULL, const = TRUE, A0 = A,
                           lmd = -log(lmd), breaks_pos = breaks_pos,
                           ur_prior = prior_params$ur_prior, mn_prior = prior_params$mn_prior,
                           v_prior = prior_params$v_prior,
                           cos_prior = prior_params$cos_prior,
                           mn_start = prior_params$mn_start, train = 0, # cores = n_varcores,
                           lmdmean = FALSE, oweights = oweights, drawbe = drawbe)

      lh <- -sum(vout$w)



      ## dirichlet prior
      if (hasLmd == TRUE){
        lpL <- apply(log(lmd) - log(nSig),2,sum) - lgamma(2 * nSig)
        lplmd <- sum(lpL) - (nSig-1) * log(nSig)
      } else {
        ## No lmd estimated for this model
        lplmd <- 0
      }


      ## Prior that selects against large eigenvalues
      ## currently not implemented

      ev <- 0
      ##might look something like:
      ## ev <- eigen(sysmat(vout$By))$values
      ## ev <- sum(abs(ev[abs(ev) > 1] - 1))^2*1e3 ##(so one root of 1.03 penalized by .9 (weak)
      ##but it could mess up MCMC logic

      lh <- lh + ev - lplmd - allh ##marginal posterior | lmd, A
      lh <- lh - jterm + pterm ## subtract the jacobian, because negative llh
      lh <- lh + prior_hp ## prior on prior parameters

    }

    if(verbose) {
      ## grab standardized residuals
      ustd <- vout$var$u
      ulevel <- vout$var$uraw ## this is always null in the rfvar3 output with non-null sigpar

      return(list(lh=lh, vout=vout, A=A, lambda = lmd, llmd = -log(lmd), u=ulevel,
                  ustd=ustd, asig = prior_params$asig, x = x, lplmd = lplmd, allh = allh)) ##llmd included because exp(-lmd) might lose precision.

    } else {
      ## print(lh)
      return(lh)

    }

  }




bvarwrap5 <-
  function(x, verbose=FALSE, dat = NULL, n_lags = 2,
           lc_A0 = NULL, lc_lmd = NULL, lmdblock = NULL,
           breaks_pos = NULL, prior_params = NULL, # n_varcores = 1,
           dprior = TRUE, hparam_nl = rep(0,5), nlt = nlt, hparam = rep(0,7),
           lmdmean = FALSE,lmdPrior = NULL,
           oweights = NULL, drawbe = FALSE) {

    ## Main function for calculating log posterior used in Metropolis step

    ## Implements a Dirichlet prior on the variances, and assumes A0 diagonal is estimated

    ## -------------------- INPUTS --------------------
    ## x: vector with all elements of A0, Lambda
    ## verbose: flag of whether to report more than the negative LLH. FALSE is useful
    ## for (some) Metropolis Hastings
    ## dat: data, in a specific format generated by other functions (see TvvDir and example scripts)
    ## n_lags: number of lags
    ## lc_A0: matrix of TRUE and FALSE indicating which elements of A0 to fill.
    ##       "unfilled" parts of matrix are diagonal
    ## lc_lmd: the full "Lmd" matrix is nshock x nregime. lc_lmd determines what parts
    ##        to fill with estimated params (in a more complicated way,
    ##        based on next arg. lmdblock, program will fill in the unspecified lambdas).
    ##        The last regime is always filled out by normalization
    ##        as nRegimes - sum(variances in previous regimes), so the arithmetic average is always
    ##        1. This is in lieu of any normalization of A0 and consistent with
    ##        a Dirichlet prior on the variances
    ## lmdblock: specifies exactly how to restrict some variances not to be
    ##        time-varying. Not used in the most recent calculations
    ## breaks_pos: vector of indices (i.e., integers) specifying the start and end
    ##        points of variance regimes. To avoid an error in counting, easiest to let
    ##        other programs populate this (you can input break points as a date string in
    ##        all the higher level programs)
    ## prior_params: struct that contains the VAR prior parameters, which are set in higher level functions.
    ## n_varcores: deprecated option for using multicore processing in calculating the
    ##           equation by equation OLS for the VAR
    ## dprior: if TRUE, use a dirichlet prior. Currently the implementation
    ##         is not very elegant, so you have to go into the code to change the parameters

    ## nlt: these are fixed parameters for the non-linear transformation. see associated functions for more info
    ## hparam_nl: these indicate (with 0 or 1) which paramters of the non-linear
    ##            transformation are being looped over (and hence added to the end of x)
    ## hparam: these indicate which prior parameters, numbered 1 to 7,
    ##         are being looped over (and included in x); i.e., being treated as heirarchical
    ##         currently: cannot loop over these and the non-linear transformation parameters

    ## lmdmean and lmdPrior: not used anymore

    ## oweights: weights on each observation to pass to likelihood
    ##          evalulation step. These are for the normal mixture models (i.e,. the "variance shocks" for each
    ##           observation)
    ## drawbe: if yes, draw the reduced form coefficients and residuals (necessary for normal mixture models)

    ## -------------------- OUTPUT --------------------
    ## if not verbose: just lh, which is the negative log posterior
    ## if verbose: lh plus a bunch of other stuff from the VAR calculation. You want this
    ##             for the normal mixture model (because it has the residuals and A_i coefficients)

    ## END PREAMBLE



    ## Preparing and formatting data ----

    ## Things that don't change, like nVar and Tobs, /should/ be bound outside
    ## the iteration, but performance gains are probably small

    nVar <- dim(dat)[2]
    Tobs <- dim(dat)[1]
    A <- matrix(0, nVar, nVar)
    varnames <- dimnames(dat)[[2]]

    ## Preparing A ----

    diag(A) <- 1
    nA <- sum(lc_A0) ##number of non-fixed parameters
    A[lc_A0] <- x[1:nA]
    dimnames(A) <- list(varnames, varnames)
    nv <- dim(A)[1]

    ## Prior on A ----

    ## Gaussian with mean 100, variance 200
    ## Prior scaling: correct if all nVar^2 parameters are non-zero
    allh <- -.5 * sum((A - diag(nVar) * 100)^2 / 4e4) -
      nVar^2 * (log (2 * pi) / 2 + log(200))

    ## Preparing lmd ----

    nLmd <- sum(lc_lmd)
    nSig <- length(breaks_pos)
    if (nLmd > 0){
      ## Fill in lambda
      lmd <- matrix(0, nVar, nSig)
      lmd[lc_lmd] <- x[nA + (1 : nLmd)]


      ## This is a streamlined way of setting certain lambda not to change between periods
      if (!is.null(lmdblock)) {
        nBlocks <- dim(lmdblock)[3]
        for (iBlock in 1:nBlocks){
          lmd[lmdblock[,,iBlock]] <- (lmd[lmdblock[,,iBlock]])[1]
          ##first of block was filled in
        }
      }

      ## last period's variances are fixed, so (arithmetic) average is 1
      ## ## lmd[,nSig] <- -log(nSig - apply(exp(-lmd[,1:(nSig-1)]),1,sum))
      lmd[,nSig] <- nSig - apply(lmd[,1:(nSig-1),drop=FALSE],1,sum)

      # check if negative log

      ## Calculate prior for lmd
      ## Dirichlet(2) for each equation
      lpL <- apply(log(lmd) - log(nSig),2,sum) - lgamma(2 * nSig)
      lplmd <- sum(lpL) - (nSig-1) * log(nSig)

    } else {
      ## lmd <- 1; no prior
      lmd <- matrix(1, nVar, nSig)
      lplmd <- 0
    }

    # testthing <-
    #   tryCatch(log(lmd), warning = function(w) "warning!")
    #
    # if(identical(testthing, "warning!")) browser()

    ## possible hyperparameters for the non-linear transformation
    lastvalue <- nA + nLmd ## for picking out extra params

    if (any(hparam_nl > 0)) { # Enter loop if any hyper parameters provided

      ## input is A, C, beta, index of param
      ## never put a prior on the last one! that would be silly
      ## dont change the 5th either, because its applied outside the function

      ## nlt[hparam_nl > 0] <- x[-(1:(nA + nLmd))]
      nlt[hparam_nl > 0] <- x[lastvalue + 1:(sum(hparam_nl > 0))]
      lastvalue <- lastvalue + sum(hparam_nl > 0)

      nlflag <- TRUE

      nlout <- transform_nl(dat, nlt) ## apply nl transform

      dat <- nlout$data ## new data
      jterm <- nlout$jterm

      pterm <- sum(hparam_nl * nlt) ## neg exponential

    } else {
      nlflag <- FALSE ## no nonlinear transformation
      jterm <- 0
      pterm <- 0
    }

    if (any(hparam > 0)){ ## hyperparameters

      ## (MN tight, MN decay, UR lambda, UR mu,
      ## Cos tight, cos smooth, cos damp)


      ## asume there is one of mn or cos prior
      if (!is.null(prior_params$cos_prior)){
        pv <- c(0,
                0,
                prior_params$ur_prior$lambda,
                prior_params$ur_prior$mu,
                prior_params$cos_prior$tight,
                prior_params$cos_prior$smooth,
                prior_params$cos_prior$damp)

        pv[(hparam > 0)] <- x[lastvalue + 1:(sum(hparam > 0))]
        ## prior_params$mn_prior$tight <- pv[1]
        ## prior_params$mn_prior$decay <- pv[2]
        prior_params$ur_prior$lambda <- pv[3]
        prior_params$ur_prior$mu <- pv[4]
        prior_params$cos_prior$tight <- pv[5]
        prior_params$cos_prior$smooth <- pv[6]
        prior_params$cos_prior$damp <- pv[7]

      } else { ## asume mn prior

        pv <- c(prior_params$mn_prior$tight,
                prior_params$mn_prior$decay,
                prior_params$ur_prior$lambda,
                prior_params$ur_prior$mu,
                0,
                0,
                0)

        pv[(hparam > 0)] <- x[lastvalue + 1:(sum(hparam > 0))]
        prior_params$mn_prior$tight <- pv[1]
        prior_params$mn_prior$decay <- pv[2]
        prior_params$ur_prior$lambda <- pv[3]
        prior_params$ur_prior$mu <- pv[4]
        ## prior_params$cos_prior$tight <- pv[5]
        ## prior_params$cos_prior$smooth <- pv[6]
        ## prior_params$cos_prior$damp <- pv[7]

      }




      prior_hp <- sum(hparam * pv) ## neg exponential density
      badflag <- any(pv < 0)
    } else {
      prior_hp <- 0
      badflag <- FALSE
    }



    ## Estimating the model ----

    if (is.null(prior_params$mn_start)) prior_params$mn_start <- 1

    if (any(lmd < 0)){
      ## trash this draw, variances negative

      lh <- 1e5
      vout <- NULL

      if (!verbose){
        return(lh) #### dont need anything else
      } else {
        return(list(lh = lh))
      }


    } else if(nlflag && any(nlt < 0)){
      ## none of the nonlinear transformation parameters can be negative
      lh <- 1e5
      vout <- NULL
      ## return(lh)

      if (!verbose){
        return(lh) #### dont need anything else
      } else {
        return(list(lh = lh))
      }


    } else if(badflag){
      ## hyperparameter cannot be negative
      lh <- 1e5
      vout <- NULL
      ## return(lh)

      if (!verbose){
        return(lh) #### dont need anything else
      } else {
        return(list(lh = lh))
      }

    } else { #### proceed normally

      vout <- SVARhtskdmdd(dat, n_lags = n_lags, xdata = NULL, const = TRUE, A0 = A,
                           lmd = -log(lmd), breaks_pos = breaks_pos,
                           ur_prior = prior_params$ur_prior, mn_prior = prior_params$mn_prior,
                           v_prior = prior_params$v_prior,
                           cos_prior = prior_params$cos_prior,
                           mn_start = prior_params$mn_start, train = 0, # cores = n_varcores,
                           lmdmean = FALSE, oweights = oweights, drawbe = drawbe)

      lh <- -sum(vout$w)

      ## Prior that selects against large eigenvalues
      ##currently not implemented
      ev <- 0
      ##might look something like:
      ## ev <- eigen(sysmat(vout$By))$values
      ## ev <- sum(abs(ev[abs(ev) > 1] - 1))^2*1e3 ##(so one root of 1.03 penalized by .9 (weak)
      ##but it could mess up MCMC logic

      ## print(lplmd)
      ##print(min(lmd))

      lh <- lh + ev - lplmd - allh ##marginal posterior | lmd, A
      lh <- lh - jterm + pterm ## subtract the jacobian, because negative llh
      lh <- lh + prior_hp ## prior on prior paraemters

    }

    if(verbose) {
      ## grab standardized residuals
      ustd <- vout$var$u
      ulevel <- vout$var$uraw ## this is always null in the rfvar3 output with non-null sigpar

      return(list(lh=lh, vout=vout, A=A, lambda = lmd, llmd = -log(lmd), u=ulevel,
                  ustd=ustd, a_sig = prior_params$a_sig, x = x, lplmd = lplmd, allh = allh)) ##llmd included because exp(-lmd) might lose precision.

    } else {
      return(lh)
    }

  }



drawdelta <-
  function(uout, alpha = .01, k = 4){

    ## draws from mixture of normals
    ## alpha is the probability OF an outlier

    ## Karthik Sastry
    ## R 3.1.2, 64 Bit
    ## August 2016

    ## END PREAMBLE



    u <- c(uout) ## treat everything symmetrically

    if (length(k) == 1){
      nprob <- dnorm(u) ## if standard
      oprob <- dnorm(u/k) ## if outlier

      post <- (alpha * oprob) / (alpha * oprob + k * (1-alpha) * nprob) ## posterior proability

      delta <- log(k) * (runif(length(u)) < post) ## take delta with this probability
    } else { ## n generalization

      scalemat <- array(rep(k, times = rep(length(u),length(k))),
                        dim = c(dim(uout),length(k)))
      alphamat <- array(rep(alpha, times = rep(length(u),length(k))),
                        dim = c(dim(uout),length(alpha)))

      ubig <- array(uout, dim = c(dim(uout),length(k)))

      ratio <- alphamat * dnorm(ubig / scalemat) / scalemat

      prob <- ratio / c(apply(ratio,c(1,2),sum)) ## normalized to probability
      cprob <- aperm(apply(prob,c(1,2),cumsum),c(2,3,1))


      ## assume alpha are ordered small to large
      delta <- matrix(0,dim(uout)[1],dim(uout)[2])
      dk <- c(log(k[1]),diff(log(k)))
      rnum <- matrix(runif(length(u)),dim(uout)[1],dim(uout)[2])

      delta  <- delta + log(scalemat[,,1]) * (rnum < cprob[,,1])

      ## dkmat <- array(rep(dk, times = rep(length(u),length(k))),
      ##                  dim = c(dim(uout),length(k)))

      for (iv in 2:length(k)){
        delta <- delta + log(scalemat[,,iv]) * (rnum > cprob[,,iv-1]) *
          (rnum < cprob[,,iv])
      }


      ## for (iv in 1:length(k)){
      ##     delta <- delta + dk[iv] * (rnum < prob[,,iv])
      ## }

      ## dkmat <- array(rep(dk, times = rep(length(u),length(k))),
      ##                  dim = c(dim(uout),length(k)))


    }

    return(matrix(delta,dim(uout)[1],dim(uout)[2]))
  }





drawt <-
  function(uout, alpha = 4, beta = alpha){

    ## draws igamma weights, for model with T errors
    ## beta is a rate, not a scale

    ## Karthik Sastry
    ## R 3.1.2, 64 Bit
    ## August 2016

    ## END PREAMBLE


    u <- c(uout) ## treat everything symmetrically

    ## delta <- rgamma(rep(alpha + 1/2,length(u)), 1/(1/beta + .5 * u^2)) ## this gives 1/sigma^2w


    palpha <- rep(alpha + 1/2,length(u))
    pbeta <-  beta + .5 * u^2

    delta <- rgamma(n = length(palpha), shape = palpha, rate = pbeta) ##1/variance units

    delta <- -log(delta)/2 ## log of standard deviation units
    return(matrix(delta,dim(uout)[1],dim(uout)[2]))
  }





fd <-
  function(delta,tparam,tscale = 1){ ## igamma tparam/2, 2/tparam

    ## returns inverse gamma density evaluated at values of matrix delta

    alpha <- tparam/2
    beta <- tparam/2 * tscale^2 ## scale, not rate

    cterm <- alpha * log(beta) - lgamma(alpha)
    xterm <- -(alpha + 1) * (2 * delta) - beta / exp(2 *  delta)

    return(sum(xterm + cterm))
  }



gdraw_1v <-
  function(ydata, xdata, olsfun, ndraw,
           x0,
           nburn = 1e3, nsep = 1e2,
           filename = 'gdraw_1v.Rdata',
           sigfactor = 0.2,
           tparam = NULL,
           tscale = 1,
           savespots = NULL,
           dscore = FALSE,
           drawdout = FALSE){

    ## Gibbs sampling for normal mixture single equation models
    ## see gdraw.R for more details

    ## Karthik Sastry
    ## R 3.1.2, 64 Bit
    ## August 2016

    ## END PREAMBLE

    ## decide where to save
    if (is.null(savespots)){
      nsaves <- 5
      inc <- ndraw %/% nsaves
      if (inc == 0){
        savespots <- ndraw ## no need to save until end
      } else {
        savespots <- c(seq(1, ndraw, inc), ndraw)
      }
    }


    ## allocate space for output
    xout <- matrix(0,length(x0),ndraw)
    lhout <- rep(0,ndraw)
    tout <- rep(0,ndraw)

    if (drawdout){
      dout <- matrix(0,length(ydata),ndraw)
    }  else {
      dout <- matrix(0,length(ydata),length(savespots))
    }

    isave <- 1 ## first save

    if (dscore){
      dsout <- rep(0,ndraw)
    } else {
      dsout <- NULL
    }

    output <- NULL

    gout <- list(xout = x0, deltaout = dout[,,1])


    ## Run the Gibbs Sampler
    if (nburn > 0){
      for (iburn in 1:nburn){
        gout <- gstep_1v(gout, olsfun, ydata, xdata,
                         tparam, tscale, dscore)
      }
    }
    for (idraw in 1:ndraw){
      for (isep in 1:nsep){
        gout <- gstep_1v(gout, olsfun, ydata, xdata,
                         tparam, tscale, dscore)
      }

      ## update
      xout[,idraw] <- gout$xout
      lhout[idraw] <- gout$lhout
      tout[idraw]  <- gout$trans
      if(drawdout) {
        dout[,idraw] <- gout$deltaout
      }

      if (dscore){
        dsout[idraw] <- gout$dsout
      }

      if (idraw %in% savespots){
        dout[,,isave] <- gout$deltaout
        isave <- isave + 1
        output <- list(xout = xout, lhout = lhout,
                       tout = tout, dout = dout,
                       dsout = dsout)
        save(output, file = filename)
      }

    }


    if (is.null(output)){
      output <- list(xout = xout, lhout = lhout,
                     tout = tout, dout = dout,
                     dsout = dsout)
    }

    save(output, file = filename)
    return(output)
  }



#' gibbs draws
#'
#' @param tvvModel
#' @param ndraw
#' @param lhfcn
#' @param nburn
#' @param nsep
#' @param filename
#' @param hsnfactor
#' @param alpha
#' @param k
#' @param tparam
#' @param tscale
#' @param savespots
#' @param dscore
#' @param drawdout
#' @param drawe
#' @param drawa
#' @param hparam_nl
#' @param nlt
#'
#' @return
#' @export
#'
gdraw <-
  function(tvvModel, ndraw, lhfcn = bvarwrap5,
           nburn = 1e3, nsep = 1e2,
           filename = 'gibbsout.Rdata',
           hsnfactor = 0.2,
           alpha = .003, k = 4,
           tparam = NULL,
           tscale = 1,
           savespots = NULL,
           dscore = FALSE,
           drawdout = FALSE, ## if TRUE, keep the delta_it (the xi_it)
           drawe = FALSE, ## if TRUE, keep the e_it
           drawa = TRUE,  ## if TRUE, keep the A+ draws
           hparam_nl = rep(0,5),        # indicates if any hyperparams for nonlinear transformation are used
           nlt = rep(0,5)               # constant parameters for nlt
  ){

    ## Main wrapper function for Gibbs Sampling from posterior of normal mixture models
    ## Note that this can also be used to sample from the Normal errors model
    ## (for instance, by setting alpha = 1 and k = 1)

    ## The real sampling happens in gstep.R

    ## --------------------INPUTS--------------------
    ## tvvModel : Output of optimization for normal errors model
    ##            <<IMPORTANT>> that this structure includes the data and some other model parameters!
    ##            So if you want to customize everything, please see TvvDir.R
    ## ndraw : Number of draws that will be //recorded//
    ## nburn : Number of initial draws discarded as burn-in. As discussed in the Appendix, etc.,
    ##         it is probably smarter to save everything and monitor convergence "manually"
    ## nsep : The separation between draws. The code is written to make nsep draws and then save
    ##        one draw, so the actual "separation" of draws is nsep-1
    ## filename : remember the extension
    ## hsnfactor : by default, the code looks at tvvModel$opt$H for a covariance matrix (inv. Hessian)
    ##             and scales it by hsnfactor (in //variance// not standard deviation units).
    ## alpha, k : specify these for the n-normal mixture model. alpha is a vector of probabilities.
    ##            k is a vector of standard deviations for each normal
    ## tparam, tscale : specify these for t errors model. tparam is df/2 (which is the first param
    ##                  for the inverse gamma distribution). tscale is the scale of the t
    ##                  which is not identified by the model and easiest to leave as unit
    ## savespots : a list of draws (between 1 asnd ndraw) at which to save. Code will generate some
    ##             automatically if left null. Note the code create a connection for output that
    ##             can be flushed at savespots to reduce memory burden
    ## dscore : save the inverse gamma density evaluated at the variance shocks, useful for MDD calculations
    ## drawdout : if TRUE, keep (save) the delta_it (called xi_it in the paper).
    ## drawe : if TRUE, keep the structural residuals
    ## drawa : if TRUE, keep the A+ (necessary for impulse responses, etc!)

    ## --------------------OUTPUT--------------------
    ## a list with elements:
    ## xout : the A0, Lambda draws
    ## lhout : the negative log posterior from metropolis step
    ## tout : 0 if there was no metropolis move, 1 if metropolis move
    ## dout : array with the delta_it (xi_it)
    ## dsout : matrix of log ig density evaluated at dout
    ## aout : A+ draws
    ## eout : structural residual draws



    ## Karthik Sastry
    ## R 3.1.2, 64 Bit
    ## August 2016

    ## END PREAMBLE


    hsn <- tvvModel$opt$H
    x0 <- tvvModel$x

    lc_A0 <- tvvModel$lc_A0
    lc_lmd <- tvvModel$lc_lmd
    ## ndraw <- nsep* ndraw + nburn
    nvar <- dim(lc_A0)[1]

    breaks_pos <- tvvModel$breaks_pos
    prior_params <- tvvModel$prior_params
    dat_ts <- tvvModel$dat_ts
    lmdblock <- tvvModel$lmdblock
    n_lags <- tvvModel$n_lags


    Sigma <- hsnfactor * hsn

    ## decide where to save
    if (is.null(savespots)){
      nsaves <- 5
      inc <- ndraw %/% nsaves
      if (inc == 0){
        savespots <- ndraw ## no need to save until end
      } else {
        savespots <- c(seq(1, ndraw, inc), ndraw)
      }
    }


    ## allocate space for output
    xout <- matrix(0,length(x0),ndraw)
    lhout <- rep(0,ndraw)
    tout <- rep(0,ndraw)

    ## always save delta, a, e in savespots
    if (drawdout){ ## delta_it
      dout <- array(0,
                    c(dim(dat_ts)[1] - n_lags,
                      dim(dat_ts)[2],
                      ndraw))
    }  else {
      dout <- array(0,
                    c(dim(dat_ts)[1] - n_lags,
                      dim(dat_ts)[2],
                      length(savespots)))
    }

    if (drawa){ ## A+
      aout <- array(0,
                    c(n_lags * nvar + 1,
                      nvar,
                      ndraw))
    }  else {
      aout <- array(0,
                    c(n_lags * nvar + 1,
                      nvar,
                      ndraw))
    }

    if (drawe){ ## epsilon_it
      eout <- array(0,
                    c(dim(dat_ts)[1] - n_lags,
                      dim(dat_ts)[2],
                      ndraw))
    }  else {
      eout <- array(0,
                    c(dim(dat_ts)[1] - n_lags,
                      dim(dat_ts)[2],
                      length(savespots)))
    }

    isave <- 1 ## first save

    if (dscore){
      dsout <- rep(0,ndraw)
    } else {
      dsout <- NULL
    }

    output <- NULL

    if (!is.null(tvvModel$dout)){
      dout[,,1] <- tvvModel$dout
    }


    gout <- list(xout = x0, deltaout = dout[,,1])


    ## Run the Gibbs Sampler
    if (nburn > 0){
      for (iburn in 1:nburn){
        gout <- gstep(gout, lhfcn, Sigma, lc_A0, lc_lmd, alpha, k,
                      lmdblock = lmdblock, breaks_pos = breaks_pos,
                      prior_params = prior_params, dat = dat_ts, n_lags = n_lags,
                      tparam = tparam, tscale = tscale, drawbe = TRUE,
                      hparam_nl = hparam_nl, nlt = nlt)
      }
    }
    for (idraw in 1:ndraw){
      for (isep in 1:nsep){
        gout <- gstep(gout, lhfcn, Sigma, lc_A0, lc_lmd, alpha, k,
                      lmdblock = lmdblock, breaks_pos = breaks_pos,
                      prior_params = prior_params, dat = dat_ts, n_lags = n_lags,
                      tparam = tparam, dscore = dscore, tscale = tscale, drawbe =TRUE,
                      hparam_nl = hparam_nl, nlt = nlt)
      }

      ## update
      xout[,idraw] <- gout$xout
      lhout[idraw] <- gout$lhout
      tout[idraw]  <- gout$trans
      if(drawdout) {
        dout[,,idraw] <- gout$deltaout
      }

      if(drawa) {
        aout[,,idraw] <- gout$aout
      }

      if(drawe) {
        eout[,,idraw] <- gout$eout
      }

      if (dscore){
        dsout[idraw] <- gout$dsout
      }
      if(idraw %% 100 ==1) print(paste(filename, "draw number", idraw))
      if (idraw %in% savespots){
        dout[,,isave] <- gout$deltaout
        isave <- isave + 1
        output <- list(xout = xout, lhout = lhout,
                       tout = tout, dout = dout,
                       dsout = dsout, aout = aout, eout = eout)
        outcon <- file(filename, open="wb")
        save(output, file = outcon)
        flush(outcon)
        close(outcon)
      }

    }

    if (is.null(output)){
      output <- list(xout = xout, lhout = lhout,
                     tout = tout, dout = dout,
                     dsout = dsout, aout = aout, eout = eout)
    }
    outcon <- file(filename, open="wb")
    save(output, file = outcon)
    flush(outcon)
    close(outcon)
    return(output)
  }



#' gets a forecast nperiods into the future
#'
#' @param tout full output of optimization
#' @param nperiods number of periods into future to forecast
#' @param Tobs Total number of observations
#'
#' @return
#' @export
#'
get_forecast <-
  function(tout,
           nperiods = 8,
           Tobs = dim(ydata)[1]){

    ## gets a forecast nperiods into the future
    ## starts at cap Tobs

    ## input to this function is full output of optimization


    ydata <- as.matrix(tout$dat_ts)

    ## get the reduced form coefficients
    A <- tout$A


    Ai <- solve(A)

    vout <- tout$vout

    By <- vout$var$By
    nv <- dim(By)[1]
    nlags <- dim(By)[3]

    Bx <- Ai %*% matrix(vout$var$Bx,nv,1)

    for (ilag in 1:nlags){
      By[,,ilag] <- Ai %*% By[,,ilag]
    }

    ## get the system matrix
    sys <- sysmat(By = By, Bx = Bx)
    ## get the data vector

    ## Tobs <- dim(ydata)[1]
    y <- matrix(0,nv,nlags)

    for (ilag in 1:nlags){
      y[,ilag] <- ydata[Tobs - ilag + 1,]
    }

    y <- c(y,1) # constant at the end

    ## calculate the predictions
    pmat <- matrix(0,nperiods,nv)

    for (iperiod in 1:nperiods){
      y <- sys %*% y
      pmat[iperiod,] <- y[1:nv]
    }

    return(pmat)
  }


#' Title Small wrapper function for calculated mdd with MHM methods
#'
#' @param x draws in a matrix
#' @param lh vector of -log posterior densities (conditional on certain params)
#' @param trunc extra piece numerator density for MHM
#' @param delta delta_it in an array, if appropriate
#' @param alpha,beta parameters for the distribution of the delta (maybe you should change this)
#' @param efac extra piece numerator density for MHM
#' @param covsub whether to calc covariance matrix with all xout, or 5000 evenly spaced draws
#'
#' @return
#' @export
#'
get_mdd <-
  function(x, lh, trunc = .95, delta = NULL,
           alpha =3, beta = 3, efac = NULL,
           covsub = FALSE){


    ## Small wrapper function for calculated mdd with MHM methods
    ## automatically puts gaussian distribution on x truncated for trunc density
    ## can put extra density in efac (e.g., on the delta_it)

    ## x is the draws in a matrix
    ## lh is a vector of -log posterior densities (conditional on certain params)
    ## efac is extra piece numerator density for MHM
    ## covsub determines whether to calc covariance matrix with all xout, or 5000 evenly spaced draws
    ## of it (mainly to save time)

    ## trunc is the truncation of the Gaussian (what percentage is kept) for A0 and Lambda
    ## delta is the delta_it in an array, if appropriate
    ## alpha and beta are for the distribution of the delta (maybe you should change this)

    ## END PREAMBLE




    ## gets estimates of the MDD for the model

    ## first, get a Gaussian approx
    xmean <- apply(x,2,mean)
    Tobs <- dim(x)[1]
    nv <- dim(x)[2]
    ## covmat <- crossprod(x) / Tobs

    if (covsub){
      ## use subsample for the covariance matrix
      xsub <- seq(from=1,to=Tobs,length.out = 5000)
      covmat <- cov(x[xsub,])
    } else {
      covmat <- cov(x)
    }

    ## If covariance matrix is near singular, add noise
    if (min(eigen(covmat)$values) < 1e-8){
      covmat <- covmat + 1e-3 * diag(dim(covmat)[1])
    }


    ## get det
    cdet <- sum(log(eigen(covmat)$values))

    ## ## evaluate gaussian approx
    ci <- (chol(solve(covmat)))
    xdm <- t(x) - xmean
    cixdm <- ci %*% xdm
    qscore <- apply(cixdm^2,2,sum) ## quadratic part

    ## qscore <- diag(t(xdm) %*% solve(covmat) %*% (xdm))

    ## qscore <- rep(0,dim(xdm)[1])
    ## for (i in 1:dim(xdm)[1]){
    ##     qscore[i] <- (xdm[i,]) %*% covmat %*% t(xdm[1,])
    ## }


    dout <- -.5 * qscore - .5 * (nv * log(2 *pi) + cdet) ## density

    kval <- qscore < qchisq(trunc,nv) ## truncate the tails of the gaussian

    if (!is.null(delta)){ ## put some distributio on the delta

      ## The conditional posterior is inverse gamma for the t case,
      ## and a known multinomial for the normal mix case
      ## so we should probably just use those distributions independent for each
      ## not what's implemented here


      dmat <- matrix(delta, dim(delta)[1] * dim(delta)[2], dim(delta)[3])

      ## ## trial 1: ivnerse gamma
      ## alpha <- 3
      ## beta <- 3 ## inverse gamma parameters
      ## dweight <- -(alpha-1) * (2 * dmat) - beta / exp(2 * dmat)
      ## dweight <- dweight + alpha * log(beta) - lgamma(alpha)

      ## ## trial 2: regular gamma
      dweight <- log(dgamma(exp(2 * dmat), shape = alpha, rate = 1/alpha))
      dweight <- apply(dweight,2,sum)
      dout <- dout + dweight
    }

    gdout <- dout + lh - log(trunc) ## before truncation

    gdmean <- mean(gdout)

    gdfix <- gdout
    gdfix[!kval] <- -1e10 ## zero values

    ##return(-(gdmean + log(mean(exp(gdfix-gdmean)))))
    if (is.null(efac)){
      return(-(gdmean + log(mean(exp(gdfix-gdmean)))))
    } else {
      m1 <- -(gdmean + log(mean(exp(gdfix-gdmean))))

      ## with the additonal correction
      gdout <- dout + efac + lh - log(trunc)


      gdmean <- mean(gdout)
      gdfix <- gdout
      gdfix[!kval] <- -1e10 ## zero values
      m2 <- -(gdmean + log(mean(exp(gdfix-gdmean))))

      outlist <- list(mout = c(m1,m2), cv = covmat)
      return(outlist)
    }
  }



#' Title get root mean squared error
#'
#' @param fcast fcast array
#' @param ydata model data for Y
#' @param h
#'
#' @return
#' @export
#'
getrmse <-
  function(fcast,ydata,h = c(1,6,12,24,48)){

    ## get root mean squared error
    ## input is "fcast" array

    nv <- dim(fcast)[2] ## number of variables
    nfc <- dim(fcast)[3] ## number of forecasts
    nh <- length(h) ## number of horizons to consider
    Tobs <- dim(ydata)[1]

    rmse <- array(0, c(nh,nv,nfc))

    for (it in 1:nfc){
      if (sum(abs(fcast[,,it])) > 1e-10){ ## make sure fc is not blank
        for (ih in 1:nh){
          hzn <- h[ih] ## what horizon
          if ((hzn + it) <= Tobs){ ## make sure there is space
            df <- fcast[1:hzn,,it] - ydata[it + 1:hzn,]
            if (hzn > 1){
              rmse[ih,,it] <- sqrt(apply(df^2,2,sum) / hzn)
            } else {
              rmse[ih,,it] <- abs(df)
            }

          }
        }
      }
    }
    return(rmse)
  }


GsnMove <-
  function(lhfcn, x0, lh0, Sigma, modeA, modeLmd, lc_A0, lc_lmd,
           verbose = FALSE, model = NULL, ordercheck = FALSE,...){

    ## One iteration of an MCMC run, using a Gaussian transition density
    ## Based off code in Chris Sims SVN directory

    ## Contains additional options to check the permutation of shocks relative
    ## to some baseline. We don't use these features in our final analysis in the paper

    ## END PREAMBLE



    x1 <- x0 + MASS::mvrnorm(n = 1, mu = rep(0, length(x0)), Sigma = Sigma)

    newmodel <- lhfcn(x1, lc_A0 = lc_A0, lc_lmd = lc_lmd, ..., verbose = TRUE)
    lh1 <- newmodel$lh



    ## trans <- ((lh0 - lh1 > log(runif(1))) && !attr(lh1, "bad"))
    trans <- (lh0 - lh1 > log(runif(1)))

    ## this logic could be better, but trying to avoid checking for reorderings if transition not accepted
    if (trans) {
      if (ordercheck) {
        mxOutput <- GetALmd(x1)
        perm <- normAlmd(mxOutput$A, mxOutput$lmd, modeA, modeLmd)
        x1 <- GetX(perm$A, perm$lmd, lcA, lc_lmd)

        reordering <- perm$noloop
      } else {
        reordering <- FALSE
      }
      lh0 <- lh1
      x0 <- x1
      model <- newmodel
    }

    if (!verbose){
      return(list(x = x0, lh = lh0, trans = trans ))
    } else {
      return(list(x = x0, lh = lh0, trans = trans, aplusmode = model$vout$var$By,
                  xxi = model$vout$var$xxi, u = model$vout$var$u,model=model))
    }

  }


gstep_1v <-
  function(gout, olsfun, ydata, xdata,
           tparam, tscale, dscore, lmdparam = NULL,Sigma = NULL){

    ## Gibbs sampling step for normal mixture single equation models
    ## see gdraw_1.R for more details

    ## Karthik Sastry
    ## R 3.1.2, 64 Bit
    ## August 2016

    ## END PREAMBLE

    if (is.null(lmdparam)){
      ## OLS step
      olsout <- olsfun(ydata,xdata,gout$deltaout)
    } else{ ## mcmc step
      lh0 <- olsfun(gout$xout,ydata,xdata,gout$deltaout,lmdparam)
      olsout <- GsnMove(olsfun,gout$xout,lh0,Sigma,
                        gout$deltaout,verbose = TRUE)
    }

    uout <- olsout$u * exp(gout$deltaout) ## multiply by last time's deltaout

    if (is.null(tparam)){
      deltaout <- drawdelta(u = uout,alpha = alpha, k = k)
    } else { ## draw inverse gamma
      deltaout <- drawt(u = uout, alpha = tparam, beta = (tscale^2) * tparam)
    }

    if (dscore){ ## reduce delta to a f(delta) for mdd calculation
      dsout <- fd(deltaout, tparam, tscale = tscale)
    } else {
      dsout <- NULL
    }

    return(list(xout = olsout$x, deltaout = deltaout,
                tout = tout, lhout = olsout$lh, dsout = dsout))

  }


gstep <-
  function(gout, lhfcn, Sigma, lc_A0, lc_lmd,
           alpha, k,
           tparam = NULL,
           tscale = 1,
           dscore = FALSE, ## if TRUE, calculate the IG density of delta_it
           ...){

    ## The main iterative step of our Gibbs sampler
    ## Note that most model-related parameters are passed in the ellipses! So see
    ## gdraw.R for more info

    ## --------------------INPUTS--------------------
    ## gout : a list which contains
    ##        xout, draw of A0 and Lambda
    ##        deltaout, draw of delta_it
    ##        trans, 1 iff metropolis step moved
    ##        lhout, negative log posterior
    ##        dsout, ig density evaluated at delta
    ##        eout, structural resids
    ##        aout, A+
    ## tparam, tscale : specify these for t errors model. tparam is df/2 (which is the first param
    ##                  for the inverse gamma distribution). tscale is the scale of the t
    ##                  which is not identified by the model and easiest to leave as unit
    ## dscore : save the inverse gamma density evaluated at the variance shocks, useful for MDD calculations

    ## --------------------OUTPUT--------------------
    ## see gout input


    ## Karthik Sastry
    ## R 3.1.2, 64 Bit
    ## August 2016

    ## END PREAMBLE


    ## markov step
    x <- gout$xout

    model <- lhfcn(x,lc_A0,lc_lmd, oweights = gout$deltaout,...,verbose = TRUE)
    almdout <- GsnMove(lhfcn, x, model$lh, Sigma,
                       modeA = NULL,
                       modeLmd = NULL,
                       lc_A0,
                       lc_lmd,
                       model = model,
                       oweights = gout$deltaout,
                       verbose = TRUE, ...)


    ## drawing the new variance weightso
    if (almdout$lh > 1e4){ ## bad draw
      ## this option should never come into play --- it would only happen if both the initial
      ## AND proposed draws were bad for some reason. It is probably possible if the variance weight
      ## from the inverse gamma is large enough to give the linear regression numerical problems, in
      ## which case you will get a singularity in the LH calculation. So this step imposes some kind of
      ## truncation on the prior for those (not completely clear what).
      return(gout)
    } else {

      ## next line does not account for the fact that we drew A+
      ## uout <- almdout$u[1:dim(gout$deltaout)[1],] * exp(gout$deltaout) ## multiply by last time's deltaout

      aout <- almdout$model$vout$var$Bdraw ## A+ draws
      eout <- almdout$model$vout$var$udraw[1:dim(gout$deltaout)[1],] * exp(gout$deltaout) ## multiply by last time's deltaout to get "real" structural resids

      if (is.null(tparam)){
        deltaout <- drawdelta(u = eout,alpha = alpha, k = k)
      } else { ## draw inverse gamma
        deltaout <- drawt(u = eout, alpha = tparam, beta = (tscale^2) * tparam)
      }

      if (dscore){ ## reduce delta to a f(delta) for mdd calculation
        dsout <- fd(deltaout, tparam)
      } else {
        dsout <- NULL
      }

      return(list(xout = almdout$x, deltaout = deltaout,
                  trans = almdout$trans, lhout = almdout$lh, dsout = dsout,
                  eout = eout, aout = aout))
    }
  }


#' Impluse plots
#'
#' @param ir
#' @param irdraws
#' @param conf
#' @param blocks
#' @param filename
#' @param format
#' @param addtitle
#' @param nsteps
#' @param shocknames
#' @param varnames
#' @param ptype
#' @param color
#' @param alpha
#' @param gr
#' @param width
#' @param height
#' @param response_ylim
#' @param xtick
#'
#' @return
#' @export
#'
#' @examples
impulseplots <-
  function(ir, ## array of impulse response objects, nvar x nshock x nperiod
           irdraws = NULL, ## nvar x nshock x nperiod x ndraw
           conf = c(.68,.90), ## what confidence bands to put on the plot
           blocks = NULL, ## possible block structure, see below for example
           filename = 'impulse_plot',
           format = 'pdf',
           addtitle = FALSE, ## put a big title on the top?
           nsteps = 60, ## number of steps to use
           shocknames = NULL, ## names of the shocks to print as titles
           varnames = rep('',dim(ir)[1]), ## names of the response variables
           ptype = 'Impulse response', ## part of the title in some cases
           color = c(0, 0, 1), ## base color (default blue)
           alpha = c(0.5,0.3), ## how much alpha for each oonf band color
           gr = 0.7, ## what shade of grey
           width = 5, ## inches
           height = 8,
           response_ylim = NULL, ## can specify the size of each response row
           xtick = NULL ## where to put xticks; default, every 12 months
  ) {

    ## Plots impulse response draws
    ## more current than other code in the same folder
    ## Handles blocking of the impulse responses into several minigarphs




    ## Some formatting issues
    ## filename = paste('/home/karthik/R/svar_kit/plotting/plots/', filename,sep='')


    if (format == 'pdf'){ ## different methods for the "light color" for pdf and eps
      shades <- grDevices::rgb(color[1], color[2], color[3], alpha)
    } else if (format == 'eps'){
      lattice::trellis.device(device="postscript", color = TRUE)
      #setEPS()
      ## grDevices::postscript(filename, width = width, height = height)

      # Cannot do transparent colors, so here is a crude workaround
      alphafy <-
        function(col,alpha=1) {
          rr <-
            1-alpha*(1-c(col/255))
          return(grDevices::rgb(rr[1],rr[2],rr[3]))
        }
      color <- alphafy(color, alpha)

    } #else raise some kind of error?

    if (is.null(varnames)){ ## get the names of each shock
      varnames <- rownames(ir)
    }

    if (is.null(xtick)){
      xtick <- seq(1,nsteps,by=12)
    }

    ##
    ## Calculating the IR quantiles and
    ## y limits for plots
    ##

    nv <- dim(ir)[1] ## variables
    ns <- dim(ir)[2] ## shocks

    ir  <- ir[,,1:nsteps] ## trimming unnecessary steps

    if (!is.null(irdraws)){
      ## get the correct quantiles
      irq <- apply(irdraws[,,1:nsteps,],1:3,quantile,
                   ##probs <- c(rev((1 - conf) / 2), .5 + conf/2))
                   probs <- c((1-conf)/2,0.5 + conf/2))
      irq <- aperm(irq,perm=c(2,3,4,1))

      nconf <- length(conf)
    } else{
      irq <- array(0,c(dim(ir),1))
      nconf <- NULL
    }

    ## determine the ylimits for each variable, if necessary
    if (is.null(response_ylim)){
      response_ylim <- matrix(0,nv,2) ## idea is that this should be identical for all blocks
      for (iv in 1:nv){
        response_ylim[iv,1] <- min(ir[iv,,],irq[iv,,,],0)
        response_ylim[iv,2] <- max(ir[iv,,],irq[iv,,,],0)
      }
    }

    ##
    ## Blocking prep
    ##

    if (is.null(blocks)){
      blocks <- list()
      blocks[[1]] <- list(x = 1:nv, y = 1:nv)
    }

    nb <- length(blocks)

    for (ib in 1:nb){

      ## open the file
      if (format == 'pdf'){
        fname <- paste(filename,'_',ib,'.pdf', sep = '')
        grDevices::pdf(fname, width = width, height = height)
      } else if (format == 'eps'){
        fname <- paste(filename,'_',ib,'.pdf', sep = '')
        lattice::trellis.device(device="postscript", color = TRUE)
        grDevices::postscript(fname,width=width,height=height)
      }


      par(mfrow = c(length(blocks[[ib]]$x),length(blocks[[ib]]$y)),
          col.lab="black",col.main="black",
          oma=c(1,5,1,2), mar=c(.5,.25,.5,.25), tcl=-0.1, mgp=c(3,1,0))


      for (rv in blocks[[ib]]$x){ ## responses

        ptitle <- varnames[rv] ## name of data series

        for (sv in blocks[[ib]]$y){ ## shocks
          plot(ir[rv,sv,],
               ylim = response_ylim[rv,],
               type = 'l',
               lwd = 0.5,
               xlab = '',
               ylab = '',
               yaxt  = 'n',
               xaxt = 'n',
               ## fg = gray(gr),
               xlim = c(1,nsteps), xaxs = 'i')

          ytick <- pretty(response_ylim[rv,],4)

          abline(h = ytick, lty = 'dotted')## ,col=gray(gr))
          abline(v = xtick, lty = 'dotted') ## ,col=gray(gr))

          abline(a=0,b=0,lwd=0.75)

          if (!is.null(nconf)){ ## plot confidence bands
            for (ic in 1:nconf){
              polygon(c(1:nsteps, nsteps:1),
                      c(irq[rv,sv,,ic],rev(irq[rv,sv,,ic+nconf])),
                      col = shades[ic],
                      border = NA)
            }
          }

          ##Adding variable name and axis on leftmost plot
          if (sv == blocks[[ib]]$y[1]){
            mtext(ptitle, side = 2, line = 5, cex = 0.5, las = 1, adj = 0)
            axis(side = 2, cex.axis = .75, las = 1,at=ytick)
          }

          ## ##Right side axis labels on right most plot
          ## if (sv == blocks[[ib]]$y[length(blocks[[ib]]$y)]){
          ##     axis(side = 4, cex.axis = .75, las = 1)
          ## }

          ##Shock name if appropriate
          if (!is.null(shocknames) &&
              rv == blocks[[ib]]$x[1]) {
            mtext(shocknames[sv], side = 3, line = 0, cex = .5)
          }
        }
      }

      if (addtitle){
        bigtitle <- paste(type, 'over', as.character(nSteps), 'periods', sep = ' ')
        title(bigtitle, outer = TRUE, cex = 1.2)
      }

      dev.off()

    }
  }



IrRun2 <-
  function(x, modeA, modeLmd, dat_ts, lc_A0, lc_lmd, n_lags = n_lags,
           owflag = FALSE, aflag = FALSE, ..., nStep = 60, rootcheck = FALSE, lrange = 1:6){
    ## Main function for drawing impulse responses
    ## It's written in a funny way, with a single draw input x, to facilitate use with
    ## lapply and its multicore version, mclapply

    ## --------------------INPUTS, for all uses--------------------
    ## x : in the base case, this includes only A0 and Lambda
    ## modeA,modeLmd : for unused parts of code that checked ordering. Set to NULL
    ## lc_A0 and lc_lmd : logical arrays showing restrictions on A0 and Lmd. Easiest to let these
    ## be populated automatically by the parent function McmcIr
    ## nStep : number of steps of impulse responses
    ## lrange : which variance regimes you want IR for. The IR are all the same up to scale

    ## --------------------INPUTS, if you've drawn A+--------------------
    ## x : vector of (A0,Lambda,A+)
    ## aflag : set to TRUE
    ## rest of stuff: doesn't really matter

    ## --------------------INPUTS, if you haven't drawn A+--------------------
    ## dat_ts : data in correct format
    ## owflag : if TRUE, delta_it are at the end of x
    ## rootcheck : if TRUE, will check if roots are stable
    ## ... : extra args passed to LH evalulation function

    ## --------------------OUTPUTS--------------------
    ## list with element ir, the impulse responses [nvar x nshock x nperiod x nregime]
    ## other stuff which is not so useful


    ## Karthik Sastry
    ## R 3.1.2, 64 Bit
    ## January 2017

    ## END PREAMBLE


    ## if (length(x) > (sum(lc_A0) + sum(lc_lmd))){ ## oweights in the mix
    if (owflag){
      oweights <- matrix(x[-(1:(sum(lc_A0) + sum(lc_lmd)))],
                         dim(dat_ts)[1] - n_lags,dim(lc_A0)[1])
    } else {
      oweights <- NULL
    }

    if (aflag){ ## aplus is already included
      dimAplus <- c(nrow(lc_A0),ncol(lc_A0),n_lags)
      Aplus <- matrix(x[-(1:(sum(lc_A0) + sum(lc_lmd)))],(nrow(lc_A0))^2,nrow(lc_A0))

      A <- matrix(0,nrow(lc_A0),ncol(lc_A0))
      A[lc_A0] <- x[1:(sum(lc_A0))]


      lambda <- matrix(0, dim(lc_lmd)[1],dim(lc_lmd)[2])
      lambda[lc_lmd] <- x[sum(lc_A0) + (1 : sum(lc_lmd))]
      lambda[,dim(lambda)[2]] <- dim(lambda)[2] -
        apply(lambda[,1:(dim(lambda)[2]-1),drop=FALSE],1,sum)

      nVar <- dim(A)[1]
      vars <- colnames(lc_A0)

      lh <- lh


    } else { ## needs to be calculated

      mlmodel <- bvarwrap5(x, dat = dat_ts, lc_A0 = lc_A0, lc_lmd = lc_lmd, oweights = oweights, verbose = TRUE, n_lags = n_lags, ...)

      lh <- mlmodel$lh

      ##add gaussian noise to A+
      ##covariance matrix
      Aplus <- mlmodel$vout$var$By
      u <- mlmodel$vout$var$u
      xx <- mlmodel$vout$var$xx
      nEq <- dim(xx)[3]
      n_lags <- dim(Aplus)[3]
      xxi <- list(nEq)
      nX <- nEq * n_lags * nEq + nEq
      ##arraySigma <- array(0, dim = c(nX, nX, nEq))
      ##xxi = solve(xx[,,1])
      for (iEq in (1:dim(xx)[3])){
        xxi[[iEq]] <- solve(xx[,,iEq])
      }
      ##getting correct Sigma matrix
      Sigma <- bdiag(xxi)
      ##coercing to matrix class....
      Sigma <- matrix(Sigma, nrow = nX)

      dimAplus <- dim(Aplus)
      ##for (iEq in 1:nEq) {
      ##	xxi[,,iEq] = solve(xx[,,iEq])
      ##}
      covu <- cov(u)
      ##Sigma <- kronecker(covu, xxi)
      ##Sigma <- kronecker(diag(dim(covu)[1]), xxi)

      ##calculating the noise
      nDraws <- dim(Sigma)[1]
      ##sndraws <- rnorm(nDraws) ##standard normal draws
      ##draws <- t(chol(Sigma)) %*% sndraws
      nAplus <- length(Aplus)
      ##mlmodel$vout$var$By <- array(c(mlmodel$vout$var$By) +  draws[1:nBy],
      ##  dim <- dim(mlmodel$vout$var$By))
      ##should not need to permute dimensions, change to matrix, etc.

      ##just to make sure, this is the postdraw() style implementation
      sndraws <- matrix(rnorm(nDraws), c(nDraws, 1))
      matAplus <- t(matrix(Aplus, nEq, nEq * n_lags))
      #### Aplusdraws <- t(chol(Sigma)) %*% sndraws
      Aplusdraws <- MASS::mvrnorm(1,rep(0,dim(Sigma)[1]),Sigma) #### new method?
      Aplusnoise <- matrix(Aplusdraws, c(nEq * n_lags + 1, nEq)) ##i.e., the matrix of noise that I am adding to the posterior mean/mode
      Aplus  <- matAplus + Aplusnoise[1:(nEq*n_lags),] ##ignoring the constant, which is last row

      ##cleaning pointers, etc.
      A <- mlmodel$A
      vout <- mlmodel$vout
      lambda <- mlmodel$lambda
      nVar <- dim(A)[1]
      vars <- colnames(A)

    }


    Aplus  <- array(t(Aplus), dim = dimAplus)

    ##Aplus <- mlmodel$vout$var$By ##cancelling variation in Aplus
    ##above I only unocmmented to see if X'X singularites were creating problems


    ##nLambdas <- dim(lambda)[2]
    ##Now a lambda range is set in the function call

    ir <- array(0, dim = c(nVar, nVar, nStep, length(lrange)))

    ##        isgood <- rep(0, nLambdas)
    ##        maxmod <- rep(0, nLambdas) ##potentially are same across variance regimes, but I want to check
    ##        maxRev <- rep(0, nLambdas)
    ##        iscomplex <- rep(0, nLambdas)

    for (iLambda in lrange){
      By <- array(0, dim = dimAplus)
      Ainv <- solve(A)
      smat <- Ainv %*% diag(sqrt(lambda[,iLambda]))
      for (iLag in (1:n_lags)) {
        By[,,iLag] <- Ainv %*% Aplus[,,iLag]
      }

      tempvar <- list()
      tempvar$By <- By
      ir[,,,which(lrange == iLambda)] <- impulsdtrf(tempvar, smat = smat, nstep = nStep)
      dimnames(ir[,,,which(lrange == iLambda)])[[1]] <- vars
    }

    newordering <- NULL ## didn't check
    badshift <- NULL
    if (rootcheck){
      rc <- CheckRoots(By)
      isgood <- rc$isgood
      maxmod <- rc$maxmod
      iscomplex <- rc$iscomplex
      maxRev <- rc$maxRev
      modmod <- rc$modmod
      return(list(ir=ir, noloop = newordering$noloop, badshift = badshift,
                  orderings = newordering$ordrng, ch = newordering$changes,
                  trimprove = newordering$trimprove, x = x, isgood = isgood,
                  maxmod = maxmod, iscomplex = iscomplex,
                  maxRev = maxRev, modmod = modmod, lh = lh))
    } else{
      return(list(ir = ir,noloop = newordering$noloop, badshift = badshift,
                  orderings = newordering$ordrng, ch = newordering$changes,
                  trimprove = newordering$trimprove, x = x, lh = lh))
    }
  }


linreg <- function(iq, lmdseries, X, ya0, drawbe = FALSE){

  errorflag <- FALSE

  wt <- exp(.5 * lmdseries[iq, ])
  ## weighting by exp(lmd/2), so log error variances are -lmd
  Xq <-  wt * X
  yq <- wt * ya0[ , iq]

  ## set up exception for weights that blow up lsfit: so
  ## minimization can proceed, knowing such models are not very likely...
  if (any(Xq == Inf) || any(yq == Inf) || any(wt < .Machine$double.eps) ||
      any(is.nan(Xq)) || any(is.na(Xq))){
    errorflag <- TRUE
    return(errorflag)
  }


  lso <- lsfit(Xq, yq, intercept=FALSE)
  ## intercept already in X. resids should be unit vce.
  ## B[ , iq] <- lso$coefficients
  Rq <- qr.R(lso$qr)
  xx <- crossprod(Rq)

  if (drawbe){ ## draw from the conditional posterior on the coefficients

    xxi <- solve(xx)

    ## coefs_noise <- MASS::mvrnorm(1,rep(0,length(lso$coefficients)),xxi)
    exxi <- eigen(xxi)
    if (any(exxi$values < 1e-14)){ ## seems like reasonable tolerance
      coefs_draw <- NULL
      udraw <- NULL
      snglty <- TRUE
      logdetxxi <- -Inf
    } else {
      coefs_noise <- exxi$vectors %*% diag(sqrt(exxi$values)) %*% rnorm(dim(xxi)[1])
      coefs_draw <- lso$coefficients + coefs_noise
      udraw <- lso$residuals - Xq %*% coefs_noise
      logdetxxi <- sum(log(exxi$values))
      snglty <- FALSE
    }
  } else { ## no coefs draw
    coefs_draw <- rep(NA,length(lso$coefficients))
    udraw <- rep(NA,length(lso$residuals))
    logdetxxi <- -2 * sum(log(abs(diag(Rq))))
    snglty <- (logdetxxi == -Inf)
  }

  ## set up exception for singular crossprod(Rq).
  ## not combined with above for debugging

  ## cp <- crossprod(Rq)
  ## if (kappa(cp) > 1/(1000*.Machine$double.eps)){ #checking condition number
  ## 	errorflag <- TRUE
  ## 	return(errorflag)
  ## }
  ## xxi[ , , iq] <- solve(cp)

  ## u[ , iq] <- lso$residuals
  ## logdetxxi[iq] <- -2 * sum(log(abs(diag(Rq))))
  ## snglty[iq] <- (logdetxxi[iq] == -Inf)


  return(list(errorflag = errorflag, coefs = lso$coefficients, u = lso$residuals,
              logdetxxi = logdetxxi, snglty = snglty, xx = xx,
              coefs_draw = coefs_draw, udraw = udraw))
}


logmean <-
  function(x){

    ## Little function to calculate harmonic means of really big or really small log quantities

    ## Karthik Sastry
    ## R 3.1.2, 64 Bit
    ## August 2016

    ## END PREAMBLE

    lm <- rep(0,4)

    ## 1. simple
    lm[1] <- log(mean(exp(x)))

    ## 2. demeaned
    mn <- mean(x)
    xdm <- x - mn
    lm[2] <- (mn) + log(mean(exp(xdm)))

    ## 3. trimmed
    lm[3] <- log(mean(exp(x), trim = 0.2))

    ## 4. trimmed dm
    lm[4] <- (mn) + log(mean(exp(xdm), trim = 0.2))

    return(lm)
  }


#' Main wrapper function for drawing impulse responses
#'
#' @param xout A0 and Lambda draws in matrix form
#' @param model
#' @param rootcheck if TRUE, will check if roots are stable
#' @param lrange which variance regimes you want IR for. The IR are all the same up to scale
#' @param cores number of cores to use for mclapply. This is easily parallelized, so use many!
#' @param oweights draws of delta_it
#' @param aplus draws of A+. Code will run a lot faster if you specify this
#' @param nStep number of steps of impulse responses
#' @param hparam
#'
#' @return list with element ir, the impulse responses [nvar x nshock x nperiod x nregime x ndraws], plus other stuff which is less useful (mainly related to orderings/permutations)
#' @export
#'
McmcIr <-
  function(xout, model, rootcheck = FALSE, lrange = 1:6, cores = 8,
           oweights = NULL,
           aplus = NULL, ## don't need both oweights and aplus
           nStep = 60, hparam = rep(0,7))
  {

    ## Main wrapper function for drawing impulse responses

    ## --------------------INPUTS, for all uses--------------------
    ## xout : A0 and Lambda draws in matrix form
    ## rootcheck : if TRUE, will check if roots are stable
    ## lrange : which variance regimes you want IR for. The IR are all the same up to scale
    ## cores: number of cores to use for mclapply. This is easily parallelized, so use many!
    ## oweights: draws of delta_it
    ## aplus : draws of A+. Code will run a lot faster if you specify this
    ## nStep : number of steps of impulse responses



    ## --------------------OUTPUTS--------------------
    ## list with element ir, the impulse responses [nvar x nshock x nperiod x nregime x ndraws]
    ## other stuff which is less useful (mainly related to orderings/permutations)

    ## Karthik Sastry
    ## R 3.1.2, 64 Bit
    ## January 2017

    ## END PREAMBLE

    vars <- colnames(model$A)

    nTrials <- dim(xout)[1]

    nX <- dim(xout)[1]
    if (is.null(nX)) {
      nX <- 1
      dim(xout) <- c(1,length(xout))
    }

    if (!is.null(oweights)){ ## add these to x
      ## xout <- cbind(xout, matrix(0,dim(xout)[1],
      ##                           dim(oweights)[1] * dim(oweights)[2]))
      ## xout[,-c(1:dim(xout)[2])] <- matrix(oweights,dim(xout)[1],
      ##                                    dim(oweights)[1] * dim(oweights)[2],
      ##                                    byrow = TRUE)

      owmat <- matrix(oweights,dim(xout)[1],
                      dim(oweights)[1] * dim(oweights)[2],
                      byrow = TRUE)
      xout <- cbind(xout, owmat)

      owflag <- TRUE
    } else {
      owflag <- FALSE
    }

    if (!is.null(aplus)){
      na <- dim(aplus)[1] ## need to remove last row
      amat <- matrix(aplus[-na,,],
                     dim(aplus)[3],
                     (na-1) * dim(aplus)[2],
                     byrow = TRUE)
      xout <- cbind(xout, amat)
      aflag <- TRUE
    } else{
      aflag <- FALSE
    }


    ## if (!is.null(aplus)){ ## add these to x
    ##     xout <- cbind(xout, matrix(0,dim(xout)[1],
    ##                               dim(oweights)[1] * dim(oweights)[2]))
    ##     xout[,-c(1:dim(xout)[2])] <- matrix(oweights,dim(xout)[1],
    ##                                        dim(oweights)[1] * dim(oweights)[2],
    ##                                        byrow = TRUE)
    ## }


    listXout <- lapply(1:nX, function(iRow){xout[iRow,]})

    listIrtrials <- parallel::mclapply(listXout, IrRun2, model$A,
                                       model$lmd, model$dat_ts,
                                       # This was formerly model$lcA, which under R shorthand
                                       # rules would have completed as the actual model$lcA0,
                                       # now renamed to model$lc_A0.
                                       # Possibly just an earlier error, Check for correctness?
                                       model$lc_A0,
                                       model$lc_lmd, n_lags = model$n_lags,
                                       owflag = owflag, aflag = aflag,
                                       lmdblock = model$lmdblock,
                                       hparam = hparam,
                                       breaks_pos = model$breaks_pos, prior_params = model$prior_params,
                                       # lmdPrior isn't used anymore,
                                       # lmdPrior = model$lmdPrior,
                                       rootcheck = rootcheck,
                                       lrange = lrange, nStep = nStep, mc.cores = cores)

    ##save(listIrtrials, file = 'rawIR.Rdata')

    ##irdim <- dim(listIrtrials[[1]]$ir)

    ##arrayIrtrials = array(sapply(listIrtrials, '[[', 1), dim = c(irdim, nTrials))

    ##percentiles <- apply(arrayIrtrials, 1:4, FUN = quantile, probs = c(.05,.5,.95))

    elements <- c('ir','ch','orderings','badshift','trimprove','x','lh')
    if (rootcheck) elements <- c(elements, 'isgood','maxmod', 'maxRev', 'iscomplex','modmod')
    output <- list()
    for (iElement in elements){
      iObject <- sapply(listIrtrials,'[[',iElement)
      if (is.null(dim(iObject))) iObject <- unlist(iObject)
      output[[iElement]] <- iObject
    }

    output$ir <- array(output$ir, dim = c(length(vars), length(vars), 60, length(lrange), nTrials))

    if (inherits(xout, 'mcmc')){
      output$x <- coda::mcmc(t(output$x), thin = thin(xout))
    }
    output$ess <- coda::effectiveSize(output$x)
    if (rootcheck) output$iscomplex <- t(output$iscomplex)

    return(output)
  }


msvreg <- function(dmat,
                   hd = 3,
                   hi = 3,
                   rel = TRUE,
                   ratio = FALSE,
                   nlag = 0,
                   verbose = FALSE,
                   ngdp = NULL){

  ## Runs single equation OLS inspired by Mian, Sufi, and Verner [and other
  ## papers in the "projection regression" literature]
  ## y_{t + hd} - y_{t} = lhs variable
  ## (c/y)_{t-1} - (c/y)_{t-1-hi} = main rhs variable
  ## for each ilag, add y_{t - ilag} - y_{t - ilag - hd}

  ## -------------------- INPUTS --------------------
  ## dmat : matrix of dependent variables. It's assumed that
  ##        column 1 is REAL output
  ##        columns 2 to N are the credit variables
  ## ngdp: specify this as a Tobs x 1 vector of nominal gdp, or log real + log price level
  ## hd and hi: size of difference for dependent and independent variables respectively
  ## rel : if TRUE, take independent variable relative to GDP
  ## ratio: if TRUE, take ind. variable as ratio to GDP
  ## nlag: number of lags of real GDP to add to right hand side
  ## verbose : if true, return (fake) data


  Tobs <- dim(dmat)[1]

  ## preparing the dep. var
  depvar <- matrix(NA,Tobs,1)
  depvar[1:(Tobs-hd)] <- dmat[(hd+1):Tobs,1] - dmat[1:(Tobs-hd),1]



  ## preparing the independent variables
  ncredit <- dim(dmat)[2] - 1
  indvar <- matrix(NA,Tobs,ncredit)

  creditvar <- dmat[,-1,drop=FALSE] ## this works no matter how many there are

  if (is.null(ngdp)){
    ## scale with real
    scalegdp <- dmat[,1]
  } else {
    scalegdp <- ngdp
  }

  if (rel){
    ## relative to GDP
    ## log ratio is one option
    creditvar <- creditvar - scalegdp

    if (ratio){
      ## but can also use the absolute ratio
      creditvar <- exp(creditvar)
    }

  }

  indvar[(hi+2):Tobs,] =
    as.matrix(creditvar[(hi+1):(Tobs-1),] - ## t-1
                creditvar[1:(Tobs-1-hi),]) ## t-1-hi
  sd <- c(sd(indvar[,1],na.rm=TRUE),sd(indvar[,2],na.rm=TRUE))

  ## adding lags if desired
  if (nlag > 0){
    lagmat <- matrix(NA,Tobs,nlag)
    diffY <- c(0,diff(c(dmat[,1])))
    for (ilag in 1:nlag){
      ## lagmat[(hd +ilag):Tobs,ilag]  <- depvar[1:(Tobs-hd-ilag)]
      lagmat[(1 +ilag):Tobs,ilag]  <- diffY[1:(Tobs-ilag)]
    }
    indvar <- cbind(indvar,lagmat)
  }

  ## running the regression
  regout <- lm(depvar ~ indvar)
  regout$sd <- sd


  if (!verbose){
    return(regout)
  } else {
    return(list(regout = regout, depvar = depvar, indvar = indvar))
  }
}








normAlmd <- function(Aml, lmdml, A, lmd) {
  if(is.null(dim(lmd))) lmd <- matrix(lmd, length(lmd), 1)
  if(is.null(dim(lmdml))) lmdml <- matrix(lmdml, length(lmdml), 1)
  nsig <- dim(lmd)[2]
  nv <- dim(lmd)[1]
  ## normalize diagonal of A, just in case
  sf <- diag(A)
  A <- (1/sf) * A
  lmd <- lmd - 2 * c(log(abs(sf)))        #vector of log sf's gets reused, col by col
  Alml <- array(0, c(nv, nv, nsig))
  Al <- Alml
  for (il in 1:nsig) {
    Alml[ , , il] <- exp(-.5 * lmdml[ , il]) * Aml
    Al[ , , il] <- exp(-.5 * lmd[ , il]) * A
  }
  Alml <- matrix(Alml, nv)
  Al <- matrix(Al, nv)
  xp <- abs(Al %*% t(Alml))
  xp <- log(xp) #better approach to avoiding zeros on diagonal, orthogonal rows, etc.
  xpo <- xp #to check later if trace actually increased
  ## xp <- abs(cor(t(Al), t(Alml)))
  ## Algorithm tries reordering up to nv times to find an invariant ordering,
  ## then gives up and returns nv'th reordering and noloop=FALSE
  ordrng <- 1:nv
  crit <- vector("numeric", nv)
  noloop <- 0
  for (ntrial in 1:nv) {
    thisOrdrng <- 1:nv
    ## Make any switch with 1 that increases trace(xp), then any with 2, etc.
    for (iv in 1:nv) {
      for (iv2 in iv:nv) {
        crit[iv2] <- xp[iv2,iv] - xp[iv,iv] + xp[iv,iv2] - xp[iv2,iv2]
      }
      idtr <- which.max(crit[iv:nv])
      newiv <- thisOrdrng[iv:nv][idtr]
      thisOrdrng[iv:nv][idtr] <- thisOrdrng[iv]
      thisOrdrng[iv] <- newiv
      Al <- Al[thisOrdrng, ]
      xp <- xp[thisOrdrng, ]
    }
    ordrng <- ordrng[thisOrdrng]
    if (all(thisOrdrng == 1:nv)) {
      noloop <- ntrial
      break
    }
  }

  trimprove <- sum(diag(xp)) >= sum(diag(xpo))


  A <- A[ordrng, ]
  sf <- diag(A)

  badshift <- any(sf < .Machine$double.eps)

  if (badshift){
    A <- Aml
    lmd <- lmdml
  } else {
    A <- (1/sf) * A
    lmd <- lmd[ordrng, ] - 2 *c(log(abs(sf)))
  }

  changes <- any(ordrng != 1:nv)
  return(list(Anormed=A , lmdnormed=lmd, ordrng=ordrng, noloop=noloop, badshift = badshift, changes = changes, trimprove = trimprove))
}


#' Title forecast plotting
#'
#' @param fcout forecasting results
#' @param ydata
#' @param dateseq
#' @param vnames
#' @param fulldates
#' @param ymat
#' @param filename
#' @param cushion
#'
#' @return
#' @export
#'
#' @examples
plotfc <- function(fcout, ydata, dateseq,
                   vnames, fulldates,
                   ymat = c(4.35,4.70,
                            4.55,4.65,
                            8.2,8.5,
                            7.00,7.40,
                            7.20,7.60,
                            -0.02,0.06,
                            5.6,6.4,
                            -0.01,0.05,
                            0.00,0.12,
                            -0.01,0.05),
                   filename = 'fcout',
                   cushion = 0){

  ## Come up with a nice way of plotting all the forecasts
  ## assume ydata starts at datseq[1]

  nfwd <- dim(fcout)[1] ## how far fwd does each fc go
  nx <- dim(fcout)[2]
  nd <- dim(fcout)[3] ## number of dates

  ## fulldates <- seq(from = datseq[1], to = datseq[nd], by = 'month') ## dates for yvec

  ymat <- matrix(ymat, nrow = 2)
  fclist <- list()

  ## make everything a time series
  for (idate in 1:nd){
    ## sdate <- seq(from = datseq[idate], length = 2, by = 'month')
    ## sdate <- sdate[2] ## month after

    sdate <- dateseq[idate]
    iy <- which(fulldates == dateseq[idate])
    yt <- ydata[iy,] # y data

    fclist[[idate]] <- ts(rbind(yt,fcout[,,idate]),
                          start =
                            c(as.numeric(format(sdate,format = '%Y')),
                              as.numeric(format(sdate,format = '%m'))),
                          frequency = 12)
    ## ylist[[idate]] = ts(yt,
    ##                     start =
    ##                         c(as.numeric(format(sdate,format = '%Y')),
    ##                           as.numeric(format(sdate,format = '%m'))),
    ##                     frequency = 12)
  }

  ## ystart = which(fulldates == dateseq[1])
  ## yend = which(fulldates == dateseq[nd]) + 1 + nfwd

  ## ytrim = ts(ydata[ystart:yend,],
  ##            start =
  ##                c(as.numeric(format(dateseq[1],format = '%Y')),
  ##                  as.numeric(format(dateseq[1],format = '%m'))),
  ##            frequency = 12)

  ytrim <- ts(ydata,
              start =
                c(as.numeric(format(fulldates[1],format = '%Y')),
                  as.numeric(format(fulldates[1],format = '%m'))),
              frequency = 12)







  grDevices::pdf(paste(filename,'.pdf',sep = ''),width = 6.5, height = 8)

  ## plotting, could be adjusted for nv
  par(mfrow = c(5,2),col.lab="black",col.main="black",
      oma=c(4,4,4,4), mar=c(2,2,2,2), tcl=-0.1, mgp=c(0,0,0))

  for (iv in 1:nx){
    plot(
      ## ts(tsdata[fullrange,iv],start = c(2006,9),frequency = 12),
      ytrim[,iv],
      type = 'l', lwd = 1.5,
      ylab = '',xlab = '',
      ylim = ymat[,iv])
    title(main = vnames[iv])

    grid(nx = NULL, ny = nx, col = "lightgray", lty = "dotted",
         lwd = 1, equilogs = TRUE)

    for (idate in 1:nd){
      lines(fclist[[idate]][,iv], lwd = .75, col = 'red')
    }
  }


  dev.off()
}


plotrmse <- function(sdate, rmse1, rmse2, rmse3, filename,
                     vname = rep(NULL,nv), ih = 1, height = 8, width = 6.5, diff = FALSE,
                     rshade = TRUE){

  nv <- dim(rmse1)[2]

  grDevices::pdf(paste(filename,'.pdf',sep = ''),height = 8, width = 6.5)

  par(mfrow = c(nv,1),col.lab="black",col.main="black",
      oma=c(1,3,1,2), mar=c(2,1,1,1), tcl=-0.1, mgp=c(0,0,0))

  nrmse <- c(1,6,12,24,48) ## number of months
  nrmse <- nrmse[ih]
  ## snip these off the end
  Tobs <- dim(rmse1)[3]

  irange <- 1:(Tobs-nrmse)

  ## rmse1 <- rmse1[,,1:(Tobs-nrmse)]
  ## rmse2 <- rmse1[,,1:(Tobs-nrmse)]
  ## rmse3 <- rmse1[,,1:(Tobs-nrmse)]

  if (rshade) {
    ## gen list of recessions
    rlist <- c(1980, 1980 + 6/12,
               1981 + 6/12,  1982 + 10/12,
               1990 + 6/12, 1991 + 2/12,
               2001 + 2/12, 2001 + 10/12,
               2007 + 11/12, 2009 + 5/12)
    rlist <- matrix(rlist,2,5)
  }


  for (iv in 1:nv){
    ## plot each variable

    if (diff){
      ## difference mode

      drmse <- rmse1[ih,iv,] - rmse2[ih,iv,]

      plot(ts(drmse,sdate,frequency = 12), type = 'l', lwd = 1,
           ylab = NULL, xlab = NULL)
      abline(a = 0, b = 0, lwd = 0.75) ## axis
      grid(lwd = .5)

    } else {
      ##ymin <- min(rmse1[ih,iv,],rmse2[ih,iv,])
      ymin <- 0
      ymax <- max(rmse1[ih,iv,],rmse2[ih,iv,]) * 1.1 ## breathing room

      ## plot(ts(rmse1[ih,iv,],sdate,frequency=12), type = 'l', lwd = .75, col = 'blue',
      ##      ylab = NULL, xlab = NULL, bty = 'l',ylim = c(ymin,ymax))

      plot(ts(rmse1[ih,iv,],sdate,frequency=12), type = 'n', lwd = .75, col = 'blue',
           ylab = NULL, xlab = NULL, bty = 'l',ylim = c(ymin,ymax), panel.first = {
             grid(lwd = 1)
           })

      if (rshade){
        for (ir in 1:5){

          polygon(c(rlist[,ir],rev(rlist[,ir])),
                  c(-1e10,-1e10,1e10,1e10),
                  col = 'grey',border = NA)
        }
      }

      lines(ts(rmse1[ih,iv,irange],sdate,frequency=12), lwd = .75, col = 'blue')
      lines(ts(rmse2[ih,iv,irange],sdate,frequency=12),lwd = .75, col = 'red')
      lines(ts(rmse3[ih,iv,irange],sdate,frequency=12),lwd = .75, col = 'green4')

      ## abline(a = 0, b = 0, lwd = 0.75) ## axis


    }


    title(main = vname[iv])


  }

  dev.off()
}


restrictVAR <-
  function(vout, type=c("3", "KF","SVhtskd"), rmat=NULL, yzrone=NULL, xzrone=NULL,
           const=NULL, cyzr=NULL, cxzr=NULL) {
    ## restrictions can be specified as rows of rmat, with coefficients applied to elements of By and Bx
    ## stacked as they are in xxi (and then repeated across the equation index), or they can be specified
    ## in yzrone, xzrone.  Each zero element of yzrone or xzrone generates a restriction that sets the corresponding
    ## coefficient in By or Bx to zero (or to a constant, if !is.null(const)).  Both kinds of restrictions
    ## can be non-trivial in the same call.

    ## type:     vout as from rfvar3 ("3") or as from rfvarKF ("KF")
    ## const:    the right hand side of rmat %*% coeff = const, not the constant in the var.
    ## cyzr, cxzr:  If using yzrone, xzrone with non-trivial constants, leave const=NULL and specify
    ##           constants with cyzr and cxzr
    ## sc:       The Schwarz criterion rejects the restriction if the chisq value plus the sc value
    ##           is positive.  This version of the sc is scale-sensitive.  Variables with higher
    ##           variance are penalized more strongly, as with a prior that expects higher-variance
    ##           variables to explain more variance.
    ##
    ## Note 2013-3-4:  Try eliminating scale effects by converting X'X to correlation matrix
    if (length(type) > 1) type <- type[1]
    if (type == "SVhtskd") {
      bvw <- vout
      vout <- bvw$vout$var
    }
    ncf <- dim(vout$By)[2] * dim(vout$By)[3] + dim(vout$Bx)[2]
    neq <- dim(vout$By)[1]
    ny <- dim(vout$By)[2]
    lags <- dim(vout$By)[3]
    nx <- dim(vout$Bx)[2]
    if (is.null(rmat)) {
      rmat <- matrix(0, 0, ncf *neq)
    }
    if (!is.null(yzrone)) {
      byz <- which(yzrone == 0, arr.ind=TRUE)
      nrstr <- dim(byz)[1]
      if (is.null( cyzr)) cyzr <- array(0, dim(yzrone))
      for (ir in 1:nrstr ) {
        newrow <- rep(0, neq * ncf)
        newrow[(byz[ir,1] - 1) * ncf + (byz[ir, 3] -1) * ny + byz[ir, 2]] <- 1
        rmat <- rbind(rmat,newrow)
      }
      const <- c(const, cyzr[byz])
    }
    if (!is.null(xzrone)) {
      bxz <- which(xzrone == 0, arr.ind=TRUE )
      nrstr <- dim(bxz)[1]
      if (is.null(cxzr)) cxzr <- matrix(0, neq, nx)
      for (ir in 1:nrstr)  {
        newrow <- rep(0,ncf * neq)
        newrow[(bxz[ir,1] - 1) * ncf + ny * lags + bxz[ir, 2]] <- 1
        rmat <- rbind(rmat, newrow)
      }
      const <- c(const, cxzr[bxz])
    }
    svdr <- svd(rmat)
    if (max(abs(svdr$d)) > 1e10 * min(abs(svdr$d))){
      error("restrictions not full rank")
    }
    ## Note that t(rv) spans the same space as rmat, so the restrictiosn are crossprod(v,coeffs)=gamma
    ## rv <- svdr$v    #2013.5.9
    if (length(type) > 1) type <- type[1]
    Tobs <- if (type == "3" || type == "SVhtskd") dim(vout$u)[1] else dim(vout$fcsterr)[1]
    if (type == "3") {
      sig <- cov(vout$u)
      svdsig <- svd(sig)
      singsig <- (max(svdsig$d) > 1e10 * min(svdsig$d))
      if(singsig) warning("Near singular sig matrix in restrictVAR")
      svdxxi <- svd(vout$xxi)
      singxxi <- (max(svdxxi$d) > 1e10 * min(svdxxi$d))
      ## if(singxxi) warning("Near singular xxi matrix in restrictVAR")
      ## schwarz <- rmat %*% kronecker(svdsig$u %*% diag(1/sqrt(svdsig$d)), svdxxi$u %*% diag(1/sqrt(svdxxi$d)))
      ##schwarz <- kronecker((1/sqrt(svdsig$d)) * t(svdsig$u), (1/sqrt(svdxxi$d)) * t(svdxxi$u)) %*% rv  #2013.5.9
      ## sqrtVb <- kronecker(sqrt(svdsig$d) * t(svdsig$u), 1/sqrt(svdxxi$d)) * t(svdxxi$u)
      ## line above seems to be a mistake, since xxi is already x'x-inverse
      sqrtVb <- kronecker(sqrt(svdsig$d) * t(svdsig$u), sqrt(svdxxi$d) * t(svdxxi$u))
      dgVb <- apply(sqrtVb^2, 2, sum)
      rmatC <- rmat %*% diag(sqrt(Tobs * dgVb))
      sqrtVbC <- sqrtVb %*% diag(1/sqrt(Tobs * dgVb))
      lndetVb <- sum(log(svdsig$d)) * dim(vout$xxi)[1] + sum(log(svdxxi$d)) * dim(sig)[1]
      lndetVbC <- lndetVb - sum(log(dgVb * Tobs))
    } else if (type == "KF") {          #type=="KF"
      svdVb <- svd(vout$Vb)
      sqrtVb <- sqrt(diag(svdVb$d)) %*% t(svdVb$u)
      dgVb <- diag(vout$Vb)
      rmatC <- rmat %*% diag(sqrt(Tobs * dgVb))
      sqrtVbC <- sqrtVb %*% diag(1/sqrt(Tobs * dgVb))
      lndetVb <- sum(log(svdVb$d))
      lndetVbC <- lndetVb - sum(log(dgVb * Tobs))
      ## schwarz <- rmat %*% svdVb$u %*% diag(1/sqrt(svdVb$d)) #below is more efficient version for large Vb
      ## schwarz <- (1/sqrt(svdVb$d)) * (t(svdVb$u) %*% rv)
    } else {                            #type="SVhtskd"
      nv <- dim(vout$By)[1]
      nX <- dim(vout$xxi)[1]
      if (is.null(nX)) nX = dim(vout$xx)[1]
      Vb <- matrix(0, nX * nv, nX * nv)


      #check if xxi is missing
      if (is.null(vout$xxi)){
        #instead we have xx, which can be inverted to get xxi
        vout$xxi = vout$xx
        for (iv in 1:nv){
          vout$xxi[,,iv] = solve(vout$xx[,,iv])
        }
      }

      for (iq in 1:nv) {
        Vb[nX * (iq-1) + 1:nX, nX * (iq-1) + 1:nX] <- vout$xxi[ , , iq]
      }

      A0i <- solve(bvw$A)
      Vb <- kronecker(A0i, diag(nX)) %*% Vb %*% kronecker(t(A0i), diag(nX))
      svdVb <- svd(Vb)

      sqrtVb <- sqrt(diag(svdVb$d)) %*% t(svdVb$u)
      # KS note: is this correct?
      sqrtVb2 = svdVb$u %*% sqrt(diag(svdVb$d)) %*% t(svdVb$u)
      dgVb <- diag(Vb)
      rmatC <- rmat %*% diag(sqrt(Tobs * dgVb))
      sqrtVbC <- sqrtVb %*% diag(1/sqrt(Tobs *dgVb))

      lndetVb <- sum(log(svdVb$d))
      lndetVbC <- lndetVb - sum(log(dgVb * Tobs))
    }

    vr2 <- (sqrtVb2 %*% t(rmat))
    cvr2 <- crossprod(vr2)
    svdvr2 <- svd(vr2)

    svdvr <- svd(sqrtVb %*% t(rmat))
    svdvrC <- svd(sqrtVbC %*% t(rmatC)) #result == line above?
    vdim1 <- dim(svdvr$u)[1]
    svdvrp <- svd(diag(vdim1) - svdvr$u %*% t(svdvr$u), nu=vdim1 - dim(rmat)[1])
    svdvrpC <- svd(diag(vdim1) - svdvrC$u %*% t(svdvrC$u), nu=vdim1 - dim(rmat)[1])
    svdvrpuv <- svd(crossprod(svdvrp$u, t(sqrtVb)))
    svdvrpuvC <- svd(crossprod(svdvrpC$u, t(sqrtVbC)))
    lndetUR <- sum(log(svdvrpuv$d))
    lndetURC <- sum(log(svdvrpuvC$d))
    df <- dim(rmat)[1]
    ## schwarz <- -2 * sum(log(diag(chol(crossprod(schwarz)))))   +  df * log(2 * pi)
    schwarz <- lndetVb - 2 * lndetUR + df * log(2 * pi)
    schwarzC <- lndetVbC - 2 * lndetURC + df * log(2 * pi)
    if(is.null(const)) const <- rep(0, dim(rmat)[1])


    if(type == "SVhtskd") {
      vout$By <- tensor::tensor(A0i, vout$By, 2, 1)
      vout$Bx <- A0i %*% vout$Bx
    }
    stackedcf <- c(t(cbind(matrix(vout$By, nrow=neq), vout$Bx)))
    gap <- rmat %*% stackedcf - const
    ##svdv <- svd(rmat %*% vout$Vb %*% t(rmat))
    chstat <- (1/svdvr$d) * t(svdvr$v) %*%  gap
    chstat <- crossprod(chstat)

    #trying with other sqrt matrix -- doesn't seem to make a difference?
    chstat4 = (1/svdvr2$d) * t(svdvr2$v) %*% gap
    chstat4 = crossprod(chstat4)

    ## # alternate method?
    ## # seems to work better
    iR <- apply(rmat == 1, 2, sum)
    rcoefs <- stackedcf
    lcR <- (iR == 1)
    rcoefs[!lcR] <- 0
    ## # rcoefs is zero for everything unrestricted, equal to coefficient for everything restricted
    chstat2 <- t(rcoefs) %*% solve(Vb) %*% rcoefs

    ## ## another alternate method : looking at implied difference in structural form coefficients
    ##    newrfc <- stackedcf
    ##    newrfc[lcR] <- 0
    ##    stackedmat <- t(cbind(matrix(vout$By, nrow = neq), vout$Bx))
    ##    newstmat <- array(newrfc, dim = dim(stackedmat))
    ##    By <- array(c(t(newstmat)), dim  = dim(vout$By))

    ##    for (i in dim(By)[3]){
    ##        By[,,i] <- bvw$A %*% By[,,i]
    ##    }

    ##    listXxi <- lapply(1:dim(vout$xxi)[3], function(i) vout$xxi[,,i])
    ##    covmat <- matrix(bdiag(listXxi), nrow = length(listXxi) * dim(listXxi[[1]])[1])

    ##    oldstack <- t(cbind(matrix(oldBy, nrow=neq), oldBx))
    ##    newstack <- t(cbind(matrix(By, nrow=neq), vout$Bx))

    ##    difference <- oldstack - newstack

    ##    chstat3 <- t(c(difference)) %*% covmat %*% c(difference)
    chstat3 <- NULL

    return(list(chiSquared=chstat, chstat2 = chstat2, chstat3 = chstat3,
                chstat4= chstat4, df=df, sc=schwarz, pval=pchisq(chstat,df),
                sc2 = schwarz - (ncf*neq-df)*log(1 - df/(neq*ncf)), scC=schwarzC))
  }


rfrun <-
  function(ydata,
           xdata = NULL,
           const = TRUE,
           lags = 8,
           nstep = 16,
           mnprior = list(tight = 3, decay = .5),
           urprior = list(lambda = 5, mu = 1),
           vprior = list(sigma = rep(.01,nv), w = 1)){

    ## runs reduced form regressions
    ## this specifies prior "externally" instead of in rfvar3

    ## -------------------- INPUTS --------------------
    ## ydata = main data for VAR
    ## xdata = any extra data for x side
    ## const = if TRUE, add constant to xdata
    ## lags = number of lags in VAR
    ## nstep = number of steps of IR to calculate
    ## mnprior, urprior, vprior: parameters for var prior


    ## so R doesnt complain later
    vnames <- colnames(ydata)
    ydata <- as.matrix(ydata)
    nv <- dim(ydata)[2]

    ## for the unit root prior
    ybar <- apply(ydata[1:lags, ], 2, mean)

    Tobs <- dim(ydata)[1]
    nv <- dim(ydata)[2]
    if (const) {
      xdata <- cbind(xdata, matrix(1,Tobs,1))
    }
    if (!is.null(xdata) ) stopifnot( dim(xdata)[1] == Tobs)
    Tx <- dim(xdata)[1]
    nx <- dim(xdata)[2]


    ## prior
    vp <- varprior(nv,nx,lags,mnprior,vprior, urprior=urprior, ybar=ybar) # vp$: ydum,xdum,pbreaks
    varp <- rfvar3(ydata = vp$ydum,
                   lags = lags,
                   xdata = vp$xdum,
                   lambda = NULL, mu = NULL, ic = NULL, const = FALSE)

    ## posterior mode of standard model
    var <- rfvar3(ydata = rbind(ydata, vp$ydum),
                  lags = lags,
                  xdata = rbind(xdata, vp$xdum),
                  lambda = NULL, mu = NULL, ic = NULL, const = FALSE,
                  breaks = matrix(c(dim(ydata)[1], dim(ydata)[1]+ vp$pbreaks),ncol=1))

    ## p. mode of model with "flat prior"
    vnp <- rfvar3(ydata = rbind(ydata),
                  lags = lags,
                  xdata = rbind(xdata),
                  lambda = NULL, mu = NULL, ic = NULL, const = FALSE)

    ## p. mode of model with only unit root prior
    vp2 <- rfvar3(ydata = rbind(ydata),
                  lags = lags,
                  xdata = rbind(xdata),
                  lambda = 5, mu = 1, ic = NULL, const = FALSE)


    ## impulse responses
    irmn <- impulsdtrf(vout = var, nstep = nstep) ## standard model
    irout <- impulsdtrf(vout = vp2, nstep = nstep) ## with just unit root prior
    irnp <- impulsdtrf(vout = vnp, nstep = nstep) ## no prior IR


    ## marginal likelihood (code is copied from a different program)
    Tu <- dim(var$u)[1]
    Tup <- dim(varp$u)[1]
    flat <- FALSE
    w <- matrictint(crossprod(var$u),var$xxi,Tu-flat*(nv+1))-flat*.5*nv*(nv+1)*log(2*pi);
    wp <- matrictint(crossprod(varp$u),varp$xxi,Tup-flat*(nv+1)/2)-flat*.5*nv*(nv+1)*log(2*pi)
    w=w-wp

    return(list(w = w, vp2 = vp2, var = var, varp = varp, vnp = vnp, irmn = irmn,
                irout = irnp, irp = irout, vnames = vnames))
  }



scaleplots <-
  function(ir1, ir2,
           ird1 = NULL,
           ird2 = NULL,
           shockscale = rep(0,10),
           filename = 'impulse_plot', format = 'pdf',
           shockvars = NULL, responsevars = NULL,
           varnames = rep('',dim(ir)[1]),
           color1 = c(0, 0, 1), gr = 0.7,
           color2 = c(1,0,0),
           width = 5, height = 8,
           conf = .68, nSteps = 60,
           ymat = NULL,
           logseries = rep(0,10),
           shocknames = NULL,
           addtitle = FALSE)
  {

    ## Plots all shocks/responses for an SVAR

    ## Code is specific to one (not very general) organization of input -- key things to preserve in a more
    ## general edit would preserve how the plots look and change how the data is processed

    ## Karthik Sastry
    ## R 3.0.2, 64 Bit
    ## First edit, June 2014


    ## END Preamble


    #### filename <- paste('/home/karthik/R/summer/macrofin/plotting','/plots/', filename,sep='')

    filename <- paste('plots/', filename,sep='')
    if (format == 'pdf'){
      filename <- paste(filename, '.pdf', sep = '')
      grDevices::pdf(filename, width = width, height = height)
      color1 <- grDevices::rgb(color1[1], color1[2], color1[3], 1)
      color2 <- grDevices::rgb(color2[1], color2[2], color2[3], 1)
    } else if (format == 'eps'){
      filename <- paste(filename, '.eps', sep = '')
      lattice::trellis.device(device="postscript", color = TRUE)
      ##setEPS()
      grDevices::postscript(filename, width = width, height = height)

      ## Cannot do transparent colors, so here is a crude workaround
      alphafy <- function(col,alpha=1) {
        rr <- 1-alpha*(1-c(col/255))
        return(grDevices::rgb(rr[1],rr[2],rr[3]))
      }
      color <- alphafy(color, alpha)

    } ##else raise some kind of error?


    ## Determining format of output ----

    ## Defaults to all structural shocks, all responses
    nVar <- dim(ir)[1]

    if (is.null(shockvars)) shockvars <- 1:nVar
    if (is.null(responsevars)) responsevars <- 1:nVar

    nShockvars <- length(shockvars)
    nRespvars <- length(responsevars)

    if (is.null(varnames)){
      varnames <- rownames(ir)
    }

    gRange <- 1:(nSteps) ##graph range
    ##In a model sense, you are only going to nSteps - 1 periods (index 1 is really period 0)

    ## Converting probability "range" into quantiles
    probs <- c(rev((1 - conf) / 2), .5 + conf/2)


    ## Scale every shock correctly
    for (ishock in shockvars){
      sval <- ir1[shockscale[ishock],
                  ishock,1]

      ir2[,ishock,] <- ir2[,ishock,] * sval / ir2[shockscale[ishock],ishock,1]
      ird1[,ishock,,] <- ird1[,ishock,,] * sval / rep(
        ird1[shockscale[ishock],ishock,1,], each = length(ird1[,ishock,,1]))

      ird2[,ishock,,] <- ird2[,ishock,,] * sval / rep(
        ird2[shockscale[ishock],ishock,1,], each = length(ird2[,ishock,,1]))
    }



    ## Plot arrangement ----

    arr <- c(nRespvars, nShockvars)

    ## par(mfrow = arr,col.lab="black",col.main="black",
    ##     oma=c(1,3,1,2), mar=c(.5,.25,.5,.25), tcl=-0.1, mgp=c(0,0,0))

    par(mfrow = arr,
        col.lab="black",col.main="black",
        oma=c(1,5,1,2), mar=c(.5,.25,.5,.25), tcl=-0.1, mgp=c(3,1,0))

    for (irsvar in responsevars) {

      irsseries_1 <- ir1[irsvar,,]
      irstrials_1 <- ird1[irsvar,,,]

      irsseries_2 <- ir2[irsvar,,]
      irstrials_2 <- ird2[irsvar,,,]


      ## Getting error bands, if appropriate
      if (!is.null(irstrials_1) & length(irstrials_1> 0)){
        irsbounds_1 <- array(NA, c(nSteps, length(probs), 10))
        for (iShock in shockvars){
          iShocktrials <- irstrials_1[iShock,,]
          iShockbounds <- t(apply(iShocktrials,1,quantile,probs = probs))
          irsbounds_1[,,iShock] <- iShockbounds[1:(nSteps),]
        }

        irsbounds_2 <- array(NA, c(nSteps, length(probs), 10))
        for (iShock in shockvars){
          iShocktrials <- irstrials_2[iShock,,]
          iShockbounds <- t(apply(iShocktrials,1,quantile,probs = probs))
          irsbounds_2[,,iShock] <- iShockbounds[1:(nSteps),]
        }

      } else {
        irsbounds <- NULL
      }

      ##Determining plot scaling/ axis size
      ##A few different reasonable approaches...

      ##yMax <- max(irsseries, irsbounds, 0) ##+ .1e-5 * abs(max(irsseries, irsbounds))
      ##yMin <- min(irsseries, irsbounds, 0) ##- 1e-5 * abs(min(irsseries, irsbounds))

      if (is.null(ymat)){
        yMax <- max(irsseries_1[shockvars,], irsbounds_1[1:nSteps,,shockvars], irsseries_2[shockvars,], irsbounds_2[1:nSteps,,shockvars], 0) ##+ .1e-5 * abs(max(irsseries, irsbounds))
        yMin <- min(irsseries_1[shockvars,], irsbounds_1[1:nSteps,,shockvars], irsseries_2[shockvars,], irsbounds_2[1:nSteps,,shockvars], 0) ##+ .1e-5 * abs(max(irsseries, irsbounds))
      } else {
        yMin <- ymat[1,irsvar]
        yMax <- ymat[2,irsvar]
      }


      for (iShockvar in shockvars){

        ##Plotting each series

        plottitle <- paste(varnames[irsvar], ' (log)'[logseries[irsvar]],
                           sep = '')

        ## if (length(probs) > 2){ #### 2 sets
        ##     upper <- irsbounds[,4,iShockvar]
        ##     lower <- irsbounds[,1,iShockvar]

        ##     p84 <- irsbounds[,3,iShockvar]
        ##     p16 <- irsbounds[,2,iShockvar]

        ## } else {
        upper1 <- irsbounds_1[,3,iShockvar]
        lower1 <- irsbounds_1[,2,iShockvar]

        upper2 <- irsbounds_2[,3,iShockvar]
        lower2 <- irsbounds_2[,2,iShockvar]

        ## p16 <- NULL
        ## p84 <- NULL
        ## }


        plot(irsseries_1[iShockvar, 1:nSteps], ylim = c(yMin, yMax), type = 'l', lwd = 1,
             xlab = '', ylab = '', yaxt = 'n', xaxt = 'n',
             ## fg = gray(gr),
             xlim = c(1,nSteps),
             xaxs = 'i',
             col = color1)
        lines(irsseries_2[iShockvar, 1:nSteps], lwd = 1, col = color2)

        abline(a = 0, b = 0, lwd = 0.75)

        lines(upper1, lwd = 1, col = color1, lty = 2)
        lines(lower1, lwd = 1, col = color1, lty = 2)

        lines(upper2, lwd = 1, col = color2, lty = 2)
        lines(lower2, lwd = 1, col = color2, lty = 2)


        ##Adding variable name and axis on leftmost plot
        if (which(shockvars == iShockvar, arr.ind = TRUE) == 1) {
          ## mtext(plottitle, side = 2, line = 2, cex = .5)
          mtext(plottitle, side = 2, line = 5, cex = 0.5, las = 1, adj = 0)
          axis(side = 2, cex.axis = .75, las = 1)
        }
        ##Right side axis labels on right most plot
        ## if (which(shockvars == iShockvar, arr.ind = TRUE) == nShockvars) {
        ##     axis(side = 4, cex.axis = .5, fg = gray(gr))
        ## }

        ##Shock name if appropriate
        if (!is.null(shocknames) && (which(responsevars == irsvar, arr.ind = TRUE) == 1)) {
          mtext(shocknames[iShockvar], side = 3, line = 0, cex = .5)
        }
      }
    }

    ## Titles ----

    if (addtitle){
      bigtitle <- paste(type, 'over', as.character(nSteps), 'periods', sep = ' ')
      title(bigtitle, outer = TRUE, cex = 1.2)
    }

    dev.off()
    ##dev.copy2pdf(file = filename)
  }


sim_model <-
  function(tvvout, ## output of optimization
           lambda = matrix(1,nv,6), ## - log variances
           lmdp = rep(10,6), ## number of periods in each regime
           burn = 0, ## number of periods in the first regime to run as "burn in"
           y0 = c(rep(0,nv*nlag),1), ## initial state
           delta = NULL ## variance modifiers
  ) {

    ## Generates fake data from our SVAR model

    ## NOTE: if delta is a scalar, the model assumes you wanted t distribution with
    ## 2*delta df, and simulates delta_it as appropriate inverse gamma



    ## Get coefficients ----

    A <- tvvout$A ## A0 matrix
    Ai <- solve(A)

    vout <- tvvout$vout

    Ap <- vout$var$By ## structural form coefficients A+
    nv <- dim(Ap)[1]
    nlag <- dim(Ap)[3]
    C <- matrix(vout$var$Bx,nv,1) ## constant

    ##
    ## Generate a system matrix
    ##

    By <- Ap ## reduced form coefs
    for (ilag in 1:nlag){
      By[,,ilag] <- Ai %*% Ap[,,ilag]
    }

    rsys <- sysmat(By,Ai %*% C) ## system for the reduced form
    ##
    ## Define a (sub) function that moves the system n steps forward
    ##

    moven <- function(x0,sysmat,n,nv,nlag,lambda,Ai){
      ## noise <- exp(-lambda) * matrix(rnorm(n * nv),nv,n)
      noise <- Ai %*% (sqrt(lambda) * matrix(rnorm(n * nv),nv,n))
      xout <- matrix(0,nv,n) ## put draws in here
      for (ii in 1:n){
        x0 <- sysmat %*% x0 + c(noise[,ii],rep(0,1 + (nlag - 1)*nv))
        xout[,ii] <- x0[1:nv]
      }
      return(list(xout = xout, xf = x0, shocks = noise))
    }

    ## translate the data into a vector, if necessary
    if (length(dim(y0)) > 1){
      ## assume the format is like
      ##       v1  v2 ....
      ## t <- 1
      ## t <- 2
      ## ...

      y0 <- c(t(y0[nlag:1,]),1)
    }

    ##
    ## Burn in, if desired
    ##

    if (burn > 0){
      lambda_burn <- matrix(lambda[,1],dim(lamda)[1],burn) ## repeat period 1 variances
      burn_in <- moven(y0,rsys,burn,nv,nlag,lambda_burn,Ai)
      y0 <- burn_in$xf
    } else {
      burn_in <- NULL
    }
    ##
    ## Run the main simulation
    ##

    replambda <- lambda[,rep(1:dim(lambda)[2],times = lmdp)]
    ## edit: drop the first 10 obs
    replambda <- replambda

    if (!is.null(delta)){ ## t case
      if (length(delta) > 1) { ## multiply by t adjusters
        replambda <- replambda * t(exp(delta)) ## log variancs
      } else { ## unconditional simulation
        gd <- 1 / rgamma(n = length(replambda), shape = delta, rate = delta)
        replambda <- replambda * gd
      }
    }

    sim_out <- moven(y0, rsys, dim(replambda)[2],
                     nv, nlag,
                     replambda,Ai)

    ##
    ## get reduced form
    ##
    ## rfsim <- t(Ai %*% sim_out$xout)

    return(list(sim_out = sim_out,
                sshocks = sim_out$shocks,
                burn_in = burn_in))
  }


SVARhtskdmdd <-
  function(ydata, n_lags, xdata=NULL, const=TRUE, A0, lmd, breaks_pos, breaks=NULL,
           ur_prior=list(lambda=5,mu=1), mn_prior=list(tight=3,decay=.5),
           v_prior=list(sig=NULL,w=1), train=0,flat=FALSE,nonorm=FALSE,ic=NULL,
           mn_start = 1, # cores = 1,
           cos_prior = NULL,
           lmdmean = FALSE, oweights = NULL,
           drawbe = FALSE)
    ### This gives the posterior integrated over A+ (the right-hand side coefficients), conditional
    ### on A0 and lmd.
    # ydata:        endogenous variable data matrix, including initial condition dates.
    ### xdata:        exogenous variable data matrix, including initial condition dates.
    ### const:        Constant term is added automatically if const=TRUE.
    ### A0:           Contemporaneous coefficient matrix --- constant.
    ### lmd:          Column Vectors of log variances of structural shocks.
    ### breaks_pos:      Dates at which lmd vectors change.  Last date with old lmd (not first with new).
    ### breaks:       breaks in the data.  The first lags data points after a break are used
    ###               as new initial conditions, not data points for the fit.
    ### lambda:       weight on the co-persistence prior dummy observation.  (5 is reasonable)
###               lambda>0 => x variables included; lambda<0 => x variables excluded;
### mn_prior       see v_prior() comments
### ur_prior:
### train:        If non-zero, this is the point in the sample at which the
###               "training sample" ends.  Prior x likelihood to this point is weighted to
###               integrate to 1, and therefore is treated as if it were itself the prior.
###               To do a pure training sample prior, set lambda=mu=0, mn_prior=NULL, v_prior$w=0,
###               train>lags.
### flat:         Even with lambda=mu=v_prior$w=0, mn_prior=NULL, det(Sigma)^(-(nv+1)/2) is used
###               as a "prior", unless flat=TRUE. flat=TRUE is likely not to work unless train is reasonably large.
### nonorm:       If true, use dummy observations but do not normalize posterior to make them a
###               proper prior.  Useful to duplicate results obtained by others, to use
###               dummy observations that do not imply a proper prior, or to save computing time in case only the
###               posterior on this model's parameters, not the weight on the model, is needed.
### ic:           Initial conditions matrix for use in forming the sums of coefficients dummy observations.
###               If ic=NULL, the means of the first lags observations in ydata are used.  If !is.null(ic),
###               ic should be a single "observation" on the y's and x's that will be used as the persistent
###               values entering the sums of coefficients dummies.
###
###               Note that to enter a prior directly as dummy observations, one can treat the
###               Dummy observations as a training sample.
###
  {
    if (is.null(dim(ydata)))  ydata <- matrix(ydata, ncol=1)
    ybar <- apply(ydata[1:n_lags, ], 2, mean)
    Tobs <- dim(ydata)[1]
    nv <- dim(ydata)[2]
    if (const) {
      xdata <- cbind(xdata, matrix(1,Tobs,1))
    }
    ## looks likely that const=FALSE, xdata=NULL case crashes.  (2012.9.24)
    if (!is.null(xdata) ) stopifnot( dim(xdata)[1] == Tobs)
    Tx <- dim(xdata)[1]
    nx <- dim(xdata)[2]

    vp <- varprior(nv,nx,n_lags,mn_prior,v_prior, ur_prior=ur_prior, ybar=ybar, mn_start = mn_start,cos_prior = cos_prior) # vp$: ydum,xdum,pbreaks

    ## -------- set lmd for prior dummies --------------
    if (is.null(dim(lmd))){
      lmdbar <- lmd ## only 1 variance regimex
    } else if (lmdmean){
      lmdbar <- apply(lmd, 1, mean) ## take mean of logs
    } else { ## zero is the arithmetic mean always
      lmdbar <- rep(0,dim(lmd)[1])
    }
    lmd <- cbind(lmd, lmdbar)


    ## -------- set A0 for prior dummies, if required ------
    if (length(dim(A0)) == 3){
      A0 <- abind::abind(A0,apply(A0,1:2,mean),along=3)
    }

    ## --------------------- breaks_pos assumed to be indexes into ydata matrix, not
    ## --------------------- dates.  Conversion from dates and adding Tobs done in bvarWrap3().
    ## breaks_pos <- c(invTime(breaks_pos, ydata), Tobs)            #dummy obs at end

    ## var <- rfvar3(ydata=rbind(ydata, vp$ydum), lags=lags, xdata=rbind(xdata,vp$xdum), breaks=matrix(c(breaks, Tobs, Tobs + vp$pbreaks), ncol=1),
    ## const=FALSE, lambda=lambda, mu=mu, ic=ic) # const is FALSE in this call because ones alread put into xdata

    ## var <- rfvar3(ydata=rbind(ydata, vp$ydum), lags=lags, xdata=rbind(xdata,vp$xdum),
    ##     breaks=matrix(c(breaks, Tobs, Tobs + vp$pbreaks), ncol=1), const=FALSE, lambda=NULL,
    ##     mu=NULL, ic=ic, sigpar=list(A0=A0,lmd=lmd,breaks_pos=breaks_pos), cores = cores)

    ## ISSUE 7/27: lmdbar is not being used for the dummies! because of the way breaks_pos is coded
    var <- rfvar3(ydata=rbind(ydata, vp$ydum), n_lags=n_lags, xdata=rbind(xdata,vp$xdum),
                  breaks=matrix(c(breaks, Tobs, Tobs + vp$pbreaks), ncol=1), const=FALSE, lambda=NULL,
                  mu=NULL, ic=ic, sigpar=list(A0=A0,lmd=lmd, breaks_pos=c(breaks_pos,Tobs)), # cores = cores,
                  oweights = oweights, drawbe = drawbe)

    if (is.null(var)) {
      return(list(w = -Inf))
    }

    ##  const is FALSE in this call because ones alread put into xdata
    Tu <- dim(var$u)[1]
    if ( any(var$snglty > 0) ) error( var$snglty, " redundant columns in rhs matrix")
    lmdllh <- .5 * sum(var$lmdseries)

    ## Check if A0 is constant or changing across regimes
    if (length(dim(A0)) == 2){
      detTerm <- determinant(A0)$modulus
    } else {

      ## Take determinants for each A0 in the list
      dets <- apply(A0,3,function(x){determinant(x)$modulus})

      ## Weighted sum of determinants
      detTerm <- sum(dets[var$freqs])/length(var$freqs)

    }


    llh <- -.5 * sum(var$u^2) + Tu * (-nv * log(2 * pi)/2 + detTerm) +
      lmdllh
    ## nb: determinant() returns log of abs value of determinant
    nX <- n_lags * nv + 1
    w <-  llh + .5 * sum(var$logdetxxi) + nv * nX * log(2 * pi)/2
    if(train!=0) {
      if(train <= n_lags)
      {
        cat("end of training sample <= # of lags\n")  #
        return
      }
      Tp <- train
      tbreaks <- c(breaks[breaks<train],Tp)
    } else {
      Tp <- n_lags
      ## because need initial conditions to form lambda/mu prior dummy obs
      tbreaks <- Tp
    }
    ytrain <- ydata[1:Tp,,drop=FALSE]
    xtrain <- xdata[1:Tp,,drop=FALSE]
    if (!nonorm) {
      prior_breaks_pos <- c(0, Tp)
      ## It is assumed that there are no breaks in lmd in the training sample!
      priornsig <- 2
      priorlmd <- cbind(lmd[ , 1], lmd[ , dim(lmd)[2]])

      if (length(dim(A0)) == 3){  # in case of time varying A0
        priorA0 <- abind::abind(A0[,,1],A0[,,dim(A0)[3]],along=3)
      } else {
        priorA0 <- A0
      }


      varp <- rfvar3(ydata=rbind(ytrain, vp$ydum), n_lags=n_lags, xdata=rbind(xtrain, vp$xdum),
                     breaks=c(tbreaks, Tp+vp$pbreaks),
                     lambda=NULL, mu=NULL, const=FALSE, ic=ic,
                     sigpar=list(A0=priorA0,lmd=priorlmd, breaks_pos=prior_breaks_pos), #cores = cores
      )
      ## const is FALSE here because xdata already has a column of ones.

      ## If regression blew up, return infinite likelihood so optimization knows not to proceed
      if (is.null(varp)){
        return(list(w = -Inf))
      }
      if (any(varp$snglty > 0)) {
        warning("Prior improper, short ", varp$snglty, " df.  Results likely nonsense.")
      } else {
        Tup <- dim(varp$u)[1]
        lmdllhp <- .5 * sum(varp$lmdseries)

        if (length(dim(A0)) == 3){  # use the prior A0

          detsp <- dets[c(1,length(dets))] # determinants for right regimes

          ## Weighted sum of determinants
          detPriorA0 <- sum(detsp[varp$freqs])/length(varp$freqs)

        } else {
          detPriorA0 <- determinant(A0)$modulus
        }

        llhp <- -.5 * sum(varp$u^2) - Tup * (nv * log(2 * pi)/2 - detPriorA0) +
          lmdllhp

        normalizer <- .5 * sum(varp$logdetxxi) + nv * nX * log(2 * pi)/2
        wp <- llhp + normalizer
        w <- w-wp
        llh <- llh - normalizer
        ## llh is height of posterior density over A0, lmd, A+ at peak.  w is height of
        ## marginal posterior for A0, lmd, with A+ integrated out.
      }
    } else {
      varp <- NULL
    }
    return(list(w=w,var=var,varp=varp,prior=list(ur_prior=ur_prior, v_prior=v_prior, mn_prior=mn_prior)))
  }



#' Priors for time series regression
#'
#'     Creates dummy observations for a prior symmetric in variables,
#'     favoring persistence.
#'
#'     The regression right-hand-side is assumed to contain lagged values, possibly
#'     of both dependent and independent variables.  By default it centers on a
#'     random walk with no effects of independent variables. The results can be used
#'     directly in \code{\link{blm}}
#'
#'    @param  vlist Character vector of names of the rhs variables
#'    @param  dvname Name of dependent variable
#'    @param  lags How many lags of each variable.  Can be a single integer,
#'            if all variables appear with the same number of lags, or a
#'            vector of integers, one for each variable. Note that this
#'            program does not care whether, when \code{lags[iv]=3}, this means that
#'            lags 1 to 3, 0 to 2, or 10 to 12 are included.
#'    @param  scale A vector, of the length of \code{vlist} plus 1, of
#'            reasonable guesses as to the standard deviations of
#'            the variables.  The last element scales the levels dummy that relates the constant to the
#'            other parameters, which should be 1.0, or smaller if guesses of variable means in vmeans are
#'            quite uncertain.
#'   @param   bbar mean of the regression coefficient vector.  Default of 1
#'            followed by zeros is reasonable when the first variable is a lagged dependent variable and this
#'            is a regression with a persistent dependent variable.  Last element
#'            is prior mean of constant (usually 0).
#'   @param   smooth The rate at which the scale of dummy observations drops as we go from low to
#'            high frequencies.  Should usually be in (0,1).  If close to zero, prior on the
#'            variable's effect is stronger at low than at high frequencies.  With smooth=1
#'            and damp=1, the prior just shrinks all coefficients toward their prior means
#'            symmetrically and independently.
#'   @param   damp The rate at which the dummy observations increase with increasing lag length. Should
#'            equal or exceed one if distant lags are more likely to be large than near-in lags.
#'   @param   erratio ratio of error variance from parameter uncertainty to error variance from the
#'            residual for the first sample observation. Keeping this constant across models of
#'            different size avoids a prior that implies big models should fit much better.
#'   @param   vmeans A priori means for the variables.  They are used in forming the last dummy observation,
#'            connecting the constant to the other coefficients.  Could be set as sample means of initial conditions.
#'            Using full sample means is problematic: the contamination of prior by data may not be a big
#'            problem for stationary data, but could be substantially distorting for non-stationary data.
#'   @return  A list with components:
#'   \itemize{
#'     \item y. Dependent variable value for dummy observations.
#'     \item X. Dummy observations implementing the prior.
#'     \item scalefac. Amount by which the prior has been scaled to match \code{erratio}.
#'   }
#'   @details Note that the last column of \code{X} is the
#'            "constant", which will *not* be a column of ones.  Generating the sample
#'            \code{X} matrix using \code{lagts()} will not by itself create a constant term in the last column.
#'            \code{lagts()} does put the variables and lags in the same order as this function.  But you have
#'            to tack on the constant vector with \code{cbind()}.  \code{X} is a matrix with column names
#'            constructed from \code{vnames} (repeated for lags).  Note that \code{lagts()} allows non-sequential lists
#'            of lags.  This program allows different lag lengths, but always \code{1:lag[iv]}.
#'  @seealso \code{\link{lagts}} for preparation of a data matrix in a form that is compatible with this
#'           function.  \code{\link{blm}} to combine the prior with data to obtain estimates.
tsregPrior <- function(vlist, dvname="y", lags=rep(0, length(vlist)), ldv=1, scale,
                       bbar=NULL, smooth, damp, vmeans, erratio) {
  nv <- length(vlist)
  nx <- if (length(lags) > 1) {
    sum(lags)
  } else {
    nv * lags
  }
  if (length(lags) == 1) {
    lags <- rep(lags, nv)
  }
  X <- matrix(0, nx + 1, nx + 1)
  nv <- length(vlist)
  js <- 0
  for (iv in 1:nv) {
    X[js + (1:lags[iv]), js + (1:lags[iv])] <- smooth^(0:(lags[iv]-1)) * ctmat(lags[iv]) %*% diag(damp^(0:(lags[iv]-1))) * scale[iv]
    js <- js + lags[iv]
  }
  X[ ,  nx+1] <- 0
  vmeans <- c(rep(vmeans, times=lags), 1)
  X[nx+1, ] <- vmeans * scale[nv + 1]
  erratio0 <- solve(t(X), vmeans)
  erratio0 <- sum(erratio0)^2
  X <- sqrt(erratio0/erratio) * X
  w <- -.5 * determinant(crossprod(X))$modulus
  if (is.null(bbar)) bbar <- c(1, rep(0,nx))
  y <- X %*% bbar
  y <- matrix(y, ncol=1, dimnames=list(NULL, dvname))
  dimnames(X)[[2]] <- c(rep(vlist, times=lags), "const")           # no indication of lags in names
  return(list(y=y, X=X, scalefac=sqrt(erratio0/erratio), call=match.call()))
}
