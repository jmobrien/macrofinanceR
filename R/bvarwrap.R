## Allows for full regime switching for A0
## Karthik Sastry
## July 1 2019

## Allows for full regime switching for A0
## Karthik Sastry
## July 1 2019


bvarwrap <-
  function(x, verbose=FALSE, dat = NULL, n_lags = 2,
           lc_A0 = NULL, lc_lmd = NULL, lmdblock = NULL,
           breaks_pos = NULL, prior_params = NULL, # n_varcores = 1,
           dprior = TRUE,
           hparam_nl = rep(0,5), nlt = nlt, hparam = rep(0,7),
           lmdmean = FALSE,lmdPrior = NULL,
           oweights = NULL, drawbe = FALSE,
           tvA = FALSE
  ) {

    ## Main function for calculating log posterior used in Metropolis step

    ## Implements a Dirichlet prior on the variances, and assumes A0 diagonal is estimated

    ## -------------------- INPUTS --------------------X
    ## x: vector with all elements of A0, Lambda
    ## verbose: flag of whether to report more than the negative LLH. FALSE is useful
    ## for (some) Metropolis Hastings
    ## dat: data, in a specific format generated by other functions (see TvvDir and example scripts)
    ## n_lags: number of lags
    ## lc_A0: matrix of TRUE and FALSE indicating which elements of A0 to fill.
    ##       "unfilled" parts of matrix are diagonal
    ## lc_lmd: the full "Lmd" matrix is nshock x nregime. lc_lmd determines what parts
    ##        to fill with estimated params (in a more complicated way,
    ##        based on next arg. lmdblock, program will fill in the unspecified lambdas).
    ##        The last regime is always filled out by normalization
    ##        as nRegimes - sum(variances in previous regimes), so the arithmetic average is always
    ##        1. This is in lieu of any normalization of A0 and consistent with
    ##        a Dirichlet prior on the variances
    ## lmdblock: specifies exactly how to restrict some variances not to be
    ##        time-varying. Not used in the most recent calculations
    ## breaks_pos: vector of indices (i.e., integers) specifying the start and end
    ##        points of variance regimes. To avoid an error in counting, easiest to let
    ##        other programs populate this (you can input break points as a date string in
    ##        all the higher level programs)
    ## prior_params: struct that contains the VAR prior parameters, which are set in higher level functions.
    ## n_varcores: deprecated option for using multicore processing in calculating the
    ##           equation by equation OLS for the VAR
    ## dprior: if TRUE, use a dirichlet prior. Currently the implementation
    ##         is not very elegant, so you have to go into the code to change the parameters

    ## nlt: these are fixed parameters for the non-linear transformation. see associated functions for more info
    ## hparam_nl: these indicate (with 0 or 1) which paramters of the non-linear
    ##            transformation are being looped over (and hence added to the end of x)
    ## hparam: these indicate which prior parameters, numbered 1 to 7,
    ##         are being looped over (and included in x); i.e., being treated as heirarchical
    ##         currently: cannot loop over these and the non-linear transformation parameters

    ## lmdmean and lmdPrior: not used anymore

    ## oweights: weights on each observation to pass to likelihood
    ##          evalulation step. These are for the normal mixture models (i.e,. the "variance shocks" for each
    ##           observation)
    ## drawbe: if yes, draw the reduced form coefficients and residuals (necessary for normal mixture models)

    ## -------------------- OUTPUT --------------------
    ## if not verbose: just lh, which is the negative log posterior
    ## if verbose: lh plus a bunch of other stuff from the VAR calculation. You want this
    ##             for the normal mixture model (because it has the residuals and A_i coefficients)

    ## END PREAMBLE

    ## Preparing and formatting data

    ## Things that don't change, like nVar and Tobs, /should/ be bound outside
    ## the iteration, but performance gains are probably small

    nVar <- dim(dat)[2]           #number of variables
    Tobs <- dim(dat)[1]
    varnames <- dimnames(dat)[[2]]
    nSig <- length(breaks_pos)              #number of regimes


    if(tvA){ # Code from bvarwrap_tvA

      ## Preparing A ----

      A <- array(0, c(nVar, nVar, nSig))   #different A matrix for each regime

      nA <- sum(lc_A0)         #number of non-fixed parameters, per regime
      Acoef <- matrix(x[1:(nA*nSig)],nrow=nA,ncol=nSig) #A parameters per regime

      for (iSig in 1:nSig){                            # fill A matrix
        Amat <- matrix(0,nVar,nVar)
        Amat[lc_A0] <- Acoef[,iSig]
        A[,,iSig] <- Amat
      }

      ## dimnames(A) <- list(varnames, varnames)
      nv <- dim(A)[1]

      ## Prior on A ----

      ## Adjusts for number of non-restircted values in A
      allh <- rep(0,nSig)
      nP <- sum(lc_A0)                      # number of parameters
      for (iSig in 1:nSig){               # looping over regimes

        Ascore <- (A[,,iSig] - diag(nVar) * 100)^2 / 4e4

        allh[iSig] <- -.5 * sum(Ascore[lc_A0]) - # subset to nonzero coefficients
          .5 * nP * (log (2 * pi) + log(200))
      }

      allh <- sum(allh)                    # summing over all variance regimes

      ## Preparing lmd ----

      if (length(x) == nA * nSig){
        ## No variance parameters to estimate
        hasLmd <- FALSE
        lmd <- matrix(1, nVar, nSig)

        nLmd <- 0

      } else {
        ## Fill in variance parameters
        hasLmd <- TRUE

        nLmd <- sum(lc_lmd)                   # maximum number of variance parameters to estimate
        lmd <- matrix(0, nVar, nSig)

        lmd[lc_lmd] <- x[(nA*nSig) + (1 : nLmd)]


        ## This is a streamlined way of setting certain lambda not to change between periods
        if (!is.null(lmdblock)) {
          nBlocks <- dim(lmdblock)[3]
          for (iBlock in 1:nBlocks){
            lmd[lmdblock[,,iBlock]] <- (lmd[lmdblock[,,iBlock]])[1]
            ##first of block was filled in
          }
        }

        ## last period's variances are fixed, so (arithmetic) average is 1
        ## ## lmd[,nSig] <- -log(nSig - apply(exp(-lmd[,1:(nSig-1)]),1,sum))
        lmd[,nSig] <- nSig - apply(lmd[,1:(nSig-1),drop=FALSE],1,sum)

        ## prior on lmd is applied later in the code

      }

    } else { # Origianl code from bvarwrap5
      ## Preparing A ----

      A <- matrix(0, nVar, nVar)

      diag(A) <- 1
      nA <- sum(lc_A0) ##number of non-fixed parameters
      A[lc_A0] <- x[1:nA]
      dimnames(A) <- list(varnames, varnames)
      nv <- dim(A)[1]

      ## Prior on A ----

      ## Gaussian with mean 100, variance 200
      ## Prior scaling: correct if all nVar^2 parameters are non-zero
      allh <- -.5 * sum((A - diag(nVar) * 100)^2 / 4e4) -
        nVar^2 * (log (2 * pi) / 2 + log(200))

      ## Preparing lmd ----

      nLmd <- sum(lc_lmd)
      nSig <- length(breaks_pos)
      if (nLmd > 0){
        ## Fill in lambda
        lmd <- matrix(0, nVar, nSig)
        lmd[lc_lmd] <- x[nA + (1 : nLmd)]


        ## This is a streamlined way of setting certain lambda not to change between periods
        if (!is.null(lmdblock)) {
          nBlocks <- dim(lmdblock)[3]
          for (iBlock in 1:nBlocks){
            lmd[lmdblock[,,iBlock]] <- (lmd[lmdblock[,,iBlock]])[1]
            ##first of block was filled in
          }
        }

        ## last period's variances are fixed, so (arithmetic) average is 1
        ## ## lmd[,nSig] <- -log(nSig - apply(exp(-lmd[,1:(nSig-1)]),1,sum))
        lmd[,nSig] <- nSig - apply(lmd[,1:(nSig-1),drop=FALSE],1,sum)

        # check if negative log

        ## Calculate prior for lmd
        ## Dirichlet(2) for each equation
        lpL <- apply(log(lmd) - log(nSig),2,sum) - lgamma(2 * nSig)
        lplmd <- sum(lpL) - (nSig-1) * log(nSig)

      } else {
        ## lmd <- 1; no prior
        lmd <- matrix(1, nVar, nSig)
        lplmd <- 0
      }

    }


    ## JMO - common section to both bvarwrap5 & _tvA

    ## possible hyperparameters for the non-linear transformation
    lastvalue <- nA + nLmd ## for picking out extra params

    if (any(hparam_nl > 0)) { # Enter loop if any hyper parameters provided

      ## input is A, C, beta, index of param
      ## never put a prior on the last one! that would be silly
      ## dont change the 5th either, because its applied outside the function

      ## nlt[hparam_nl > 0] <- x[-(1:(nA + nLmd))]
      nlt[hparam_nl > 0] <- x[lastvalue + 1:(sum(hparam_nl > 0))]
      lastvalue <- lastvalue + sum(hparam_nl > 0)

      nlflag <- TRUE

      nlout <- transform_nl(dat, nlt) ## apply nl transform

      dat <- nlout$data ## new data
      jterm <- nlout$jterm

      pterm <- sum(hparam_nl * nlt) ## neg exponential

    } else {
      nlflag <- FALSE ## no nonlinear transformation
      jterm <- 0
      pterm <- 0
    }

    if (any(hparam > 0)){ ## hyperparameters

      ## (MN tight, MN decay, UR lambda, UR mu,
      ## Cos tight, cos smooth, cos damp)


      ## asume there is one of mn or cos prior
      if (!is.null(prior_params$cos_prior)){
        pv <- c(0,
                0,
                prior_params$ur_prior$lambda,
                prior_params$ur_prior$mu,
                prior_params$cos_prior$tight,
                prior_params$cos_prior$smooth,
                prior_params$cos_prior$damp)

        pv[(hparam > 0)] <- x[lastvalue + 1:(sum(hparam > 0))]
        ## prior_params$mn_prior$tight <- pv[1]
        ## prior_params$mn_prior$decay <- pv[2]
        prior_params$ur_prior$lambda <- pv[3]
        prior_params$ur_prior$mu <- pv[4]
        prior_params$cos_prior$tight <- pv[5]
        prior_params$cos_prior$smooth <- pv[6]
        prior_params$cos_prior$damp <- pv[7]

      } else { ## asume mn prior

        pv <- c(prior_params$mn_prior$tight,
                prior_params$mn_prior$decay,
                prior_params$ur_prior$lambda,
                prior_params$ur_prior$mu,
                0,
                0,
                0)

        pv[(hparam > 0)] <- x[lastvalue + 1:(sum(hparam > 0))]
        prior_params$mn_prior$tight <- pv[1]
        prior_params$mn_prior$decay <- pv[2]
        prior_params$ur_prior$lambda <- pv[3]
        prior_params$ur_prior$mu <- pv[4]
        ## prior_params$cos_prior$tight <- pv[5]
        ## prior_params$cos_prior$smooth <- pv[6]
        ## prior_params$cos_prior$damp <- pv[7]

      }

      prior_hp <- sum(hparam * pv) ## neg exponential density
      badflag <- any(pv < 0)
    } else {
      prior_hp <- 0
      badflag <- FALSE
    }



    ## Estimating the model ----


    if (is.null(prior_params$mn_start)) prior_params$mn_start <- 1

    if (any(lmd < 0)){
      ## trash this draw, variances negative

      lh <- 1e5
      vout <- NULL

      if (!verbose){
        return(lh) #### dont need anything else
      } else {
        return(list(lh = lh))
      }


    } else if(nlflag && any(nlt < 0)){
      ## none of the nonlinear transformation parameters can be negative
      lh <- 1e5
      vout <- NULL
      ## return(lh)

      if (!verbose){
        return(lh) #### dont need anything else
      } else {
        return(list(lh = lh))
      }


    } else if(badflag){
      ## hyperparameter cannot be negative
      lh <- 1e5
      vout <- NULL
      ## return(lh)

      if (!verbose){
        return(lh) #### dont need anything else
      } else {
        return(list(lh = lh))
      }

    } else { #### proceed normally


      vout <- SVARhtskdmdd(dat, n_lags = n_lags, xdata = NULL, const = TRUE, A0 = A,
                           lmd = -log(lmd), breaks_pos = breaks_pos,
                           ur_prior = prior_params$ur_prior, mn_prior = prior_params$mn_prior,
                           v_prior = prior_params$v_prior,
                           cos_prior = prior_params$cos_prior,
                           mn_start = prior_params$mn_start, train = 0, # cores = n_varcores,
                           lmdmean = FALSE, oweights = oweights, drawbe = drawbe)

      lh <- -sum(vout$w)


      ## JMO another section differentiating bvarwrap5 & _tvA, this addition:
      if(tvA){

        ## dirichlet prior
        if (hasLmd == TRUE){
          lpL <- apply(log(lmd) - log(nSig),2,sum) - lgamma(2 * nSig)
          lplmd <- sum(lpL) - (nSig-1) * log(nSig)
        } else {
          ## No lmd estimated for this model
          lplmd <- 0
        }

      }


      ## Prior that selects against large eigenvalues
      ## currently not implemented
      ev <- 0
      ##might look something like:
      ## ev <- eigen(sysmat(vout$By))$values
      ## ev <- sum(abs(ev[abs(ev) > 1] - 1))^2*1e3 ##(so one root of 1.03 penalized by .9 (weak)
      ##but it could mess up MCMC logic

      lh <- lh + ev - lplmd - allh ##marginal posterior | lmd, A
      lh <- lh - jterm + pterm ## subtract the jacobian, because negative llh
      lh <- lh + prior_hp ## prior on prior parameters

    }

    if(verbose) {
      ## grab standardized residuals
      ustd <- vout$var$u
      ulevel <- vout$var$uraw ## this is always null in the rfvar3 output with non-null sigpar

      return(list(lh=lh, vout=vout, A=A, lambda = lmd, llmd = -log(lmd), u=ulevel,
                  ustd=ustd, asig = prior_params$asig, x = x, lplmd = lplmd, allh = allh)) ##llmd included because exp(-lmd) might lose precision.

    } else {
      ## print(lh)
      return(lh)

    }

  }



SVARhtskdmdd <-
  function(ydata, n_lags, xdata=NULL, const=TRUE, A0, lmd, breaks_pos, breaks=NULL,
           ur_prior=list(lambda=5,mu=1), mn_prior=list(tight=3,decay=.5),
           v_prior=list(sig=NULL,w=1), train=0,flat=FALSE,nonorm=FALSE,ic=NULL,
           mn_start = 1, # cores = 1,
           cos_prior = NULL,
           lmdmean = FALSE, oweights = NULL,
           drawbe = FALSE)
    ### This gives the posterior integrated over A+ (the right-hand side coefficients), conditional
    ### on A0 and lmd.
    # ydata:        endogenous variable data matrix, including initial condition dates.
    ### xdata:        exogenous variable data matrix, including initial condition dates.
    ### const:        Constant term is added automatically if const=TRUE.
    ### A0:           Contemporaneous coefficient matrix --- constant.
    ### lmd:          Column Vectors of log variances of structural shocks.
    ### breaks_pos:      Dates at which lmd vectors change.  Last date with old lmd (not first with new).
    ### breaks:       breaks in the data.  The first lags data points after a break are used
    ###               as new initial conditions, not data points for the fit.
    ### lambda:       weight on the co-persistence prior dummy observation.  (5 is reasonable)
###               lambda>0 => x variables included; lambda<0 => x variables excluded;
### mn_prior       see v_prior() comments
### ur_prior:
### train:        If non-zero, this is the point in the sample at which the
###               "training sample" ends.  Prior x likelihood to this point is weighted to
###               integrate to 1, and therefore is treated as if it were itself the prior.
###               To do a pure training sample prior, set lambda=mu=0, mn_prior=NULL, v_prior$w=0,
###               train>lags.
### flat:         Even with lambda=mu=v_prior$w=0, mn_prior=NULL, det(Sigma)^(-(nv+1)/2) is used
###               as a "prior", unless flat=TRUE. flat=TRUE is likely not to work unless train is reasonably large.
### nonorm:       If true, use dummy observations but do not normalize posterior to make them a
###               proper prior.  Useful to duplicate results obtained by others, to use
###               dummy observations that do not imply a proper prior, or to save computing time in case only the
###               posterior on this model's parameters, not the weight on the model, is needed.
### ic:           Initial conditions matrix for use in forming the sums of coefficients dummy observations.
###               If ic=NULL, the means of the first lags observations in ydata are used.  If !is.null(ic),
###               ic should be a single "observation" on the y's and x's that will be used as the persistent
###               values entering the sums of coefficients dummies.
###
###               Note that to enter a prior directly as dummy observations, one can treat the
###               Dummy observations as a training sample.
###
  {
    if (is.null(dim(ydata)))  ydata <- matrix(ydata, ncol=1)
    ybar <- apply(ydata[1:n_lags, ], 2, mean)
    Tobs <- dim(ydata)[1]
    nv <- dim(ydata)[2]
    if (const) {
      xdata <- cbind(xdata, matrix(1,Tobs,1))
    }
    ## looks likely that const=FALSE, xdata=NULL case crashes.  (2012.9.24)
    if (!is.null(xdata) ) stopifnot( dim(xdata)[1] == Tobs)
    Tx <- dim(xdata)[1]
    nx <- dim(xdata)[2]

    vp <- varprior(nv,nx,n_lags,mn_prior,v_prior, ur_prior=ur_prior, ybar=ybar, mn_start = mn_start,cos_prior = cos_prior) # vp$: ydum,xdum,pbreaks

    ## -------- set lmd for prior dummies --------------
    if (is.null(dim(lmd))){
      lmdbar <- lmd ## only 1 variance regimex
    } else if (lmdmean){
      lmdbar <- apply(lmd, 1, mean) ## take mean of logs
    } else { ## zero is the arithmetic mean always
      lmdbar <- rep(0,dim(lmd)[1])
    }
    lmd <- cbind(lmd, lmdbar)


    ## -------- set A0 for prior dummies, if required ------
    if (length(dim(A0)) == 3){
      A0 <- abind::abind(A0,apply(A0,1:2,mean),along=3)
    }

    ## --------------------- breaks_pos assumed to be indexes into ydata matrix, not
    ## --------------------- dates.  Conversion from dates and adding Tobs done in bvarWrap3().
    ## breaks_pos <- c(invTime(breaks_pos, ydata), Tobs)            #dummy obs at end

    ## var <- rfvar3(ydata=rbind(ydata, vp$ydum), lags=lags, xdata=rbind(xdata,vp$xdum), breaks=matrix(c(breaks, Tobs, Tobs + vp$pbreaks), ncol=1),
    ## const=FALSE, lambda=lambda, mu=mu, ic=ic) # const is FALSE in this call because ones alread put into xdata

    ## var <- rfvar3(ydata=rbind(ydata, vp$ydum), lags=lags, xdata=rbind(xdata,vp$xdum),
    ##     breaks=matrix(c(breaks, Tobs, Tobs + vp$pbreaks), ncol=1), const=FALSE, lambda=NULL,
    ##     mu=NULL, ic=ic, sigpar=list(A0=A0,lmd=lmd,breaks_pos=breaks_pos), cores = cores)

    ## ISSUE 7/27: lmdbar is not being used for the dummies! because of the way breaks_pos is coded
    var <- rfvar3(ydata=rbind(ydata, vp$ydum), n_lags=n_lags, xdata=rbind(xdata,vp$xdum),
                  breaks=matrix(c(breaks, Tobs, Tobs + vp$pbreaks), ncol=1), const=FALSE, lambda=NULL,
                  mu=NULL, ic=ic, sigpar=list(A0=A0,lmd=lmd, breaks_pos=c(breaks_pos,Tobs)), # cores = cores,
                  oweights = oweights, drawbe = drawbe)

    if (is.null(var)) {
      return(list(w = -Inf))
    }

    ##  const is FALSE in this call because ones alread put into xdata
    Tu <- dim(var$u)[1]
    if ( any(var$snglty > 0) ) error( var$snglty, " redundant columns in rhs matrix")
    lmdllh <- .5 * sum(var$lmdseries)

    ## Check if A0 is constant or changing across regimes
    if (length(dim(A0)) == 2){
      detTerm <- determinant(A0)$modulus
    } else {

      ## Take determinants for each A0 in the list
      dets <- apply(A0,3,function(x){determinant(x)$modulus})

      ## Weighted sum of determinants
      detTerm <- sum(dets[var$freqs])/length(var$freqs)

    }


    llh <- -.5 * sum(var$u^2) + Tu * (-nv * log(2 * pi)/2 + detTerm) +
      lmdllh
    ## nb: determinant() returns log of abs value of determinant
    nX <- n_lags * nv + 1
    w <-  llh + .5 * sum(var$logdetxxi) + nv * nX * log(2 * pi)/2
    if(train!=0) {
      if(train <= n_lags)
      {
        cat("end of training sample <= # of lags\n")  #
        return
      }
      Tp <- train
      tbreaks <- c(breaks[breaks<train],Tp)
    } else {
      Tp <- n_lags
      ## because need initial conditions to form lambda/mu prior dummy obs
      tbreaks <- Tp
    }
    ytrain <- ydata[1:Tp,,drop=FALSE]
    xtrain <- xdata[1:Tp,,drop=FALSE]
    if (!nonorm) {
      prior_breaks_pos <- c(0, Tp)
      ## It is assumed that there are no breaks in lmd in the training sample!
      priornsig <- 2
      priorlmd <- cbind(lmd[ , 1], lmd[ , dim(lmd)[2]])

      if (length(dim(A0)) == 3){  # in case of time varying A0
        priorA0 <- abind::abind(A0[,,1],A0[,,dim(A0)[3]],along=3)
      } else {
        priorA0 <- A0
      }


      varp <- rfvar3(ydata=rbind(ytrain, vp$ydum), n_lags=n_lags, xdata=rbind(xtrain, vp$xdum),
                     breaks=c(tbreaks, Tp+vp$pbreaks),
                     lambda=NULL, mu=NULL, const=FALSE, ic=ic,
                     sigpar=list(A0=priorA0,lmd=priorlmd, breaks_pos=prior_breaks_pos), #cores = cores
      )
      ## const is FALSE here because xdata already has a column of ones.

      ## If regression blew up, return infinite likelihood so optimization knows not to proceed
      if (is.null(varp)){
        return(list(w = -Inf))
      }
      if (any(varp$snglty > 0)) {
        warning("Prior improper, short ", varp$snglty, " df.  Results likely nonsense.")
      } else {
        Tup <- dim(varp$u)[1]
        lmdllhp <- .5 * sum(varp$lmdseries)

        if (length(dim(A0)) == 3){  # use the prior A0

          detsp <- dets[c(1,length(dets))] # determinants for right regimes

          ## Weighted sum of determinants
          detPriorA0 <- sum(detsp[varp$freqs])/length(varp$freqs)

        } else {
          detPriorA0 <- determinant(A0)$modulus
        }

        llhp <- -.5 * sum(varp$u^2) - Tup * (nv * log(2 * pi)/2 - detPriorA0) +
          lmdllhp

        normalizer <- .5 * sum(varp$logdetxxi) + nv * nX * log(2 * pi)/2
        wp <- llhp + normalizer
        w <- w-wp
        llh <- llh - normalizer
        ## llh is height of posterior density over A0, lmd, A+ at peak.  w is height of
        ## marginal posterior for A0, lmd, with A+ integrated out.
      }
    } else {
      varp <- NULL
    }
    return(list(w=w,var=var,varp=varp,prior=list(ur_prior=ur_prior, v_prior=v_prior, mn_prior=mn_prior)))
  }
